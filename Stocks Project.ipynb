{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning) # get rid of depreciation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/jacobbills/Desktop/Economics/Twitter_sentiment_DJIA30/Combined_stocks.csv\") \n",
    "#brings in the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some percents for the different sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14182 entries, 0 to 14181\n",
      "Data columns (total 56 columns):\n",
      "Unnamed: 0    14182 non-null int64\n",
      "Date          14182 non-null object\n",
      "HIGH          14182 non-null float64\n",
      "CLOSE         14182 non-null float64\n",
      "OPEN          14182 non-null float64\n",
      "LOW           14182 non-null float64\n",
      "NUM_NEG       14182 non-null int64\n",
      "NUM_NEU       14182 non-null int64\n",
      "NUM_POS       14182 non-null int64\n",
      "TW            14182 non-null int64\n",
      "weekend       14182 non-null int64\n",
      "NUM_NEG1      14182 non-null int64\n",
      "NUM_NEG2      14182 non-null int64\n",
      "NUM_NEG3      14182 non-null int64\n",
      "NUM_NEU1      14182 non-null int64\n",
      "NUM_NEU2      14182 non-null int64\n",
      "NUM_NEU3      14182 non-null int64\n",
      "NUM_POS1      14182 non-null int64\n",
      "NUM_POS2      14182 non-null int64\n",
      "NUM_POS3      14182 non-null int64\n",
      "TW1           14182 non-null int64\n",
      "TW2           14182 non-null int64\n",
      "TW3           14182 non-null int64\n",
      "CLOSE1        14182 non-null float64\n",
      "CLOSE2        14182 non-null float64\n",
      "CLOSE3        14182 non-null float64\n",
      "AXP           14182 non-null int64\n",
      "BA            14182 non-null int64\n",
      "CAT           14182 non-null int64\n",
      "CSCO          14182 non-null int64\n",
      "CVX           14182 non-null int64\n",
      "DD            14182 non-null int64\n",
      "DIS           14182 non-null int64\n",
      "GE            14182 non-null int64\n",
      "GS            14182 non-null int64\n",
      "HD            14182 non-null int64\n",
      "IBM           14182 non-null int64\n",
      "INTC          14182 non-null int64\n",
      "JNJ           14182 non-null int64\n",
      "JPM           14182 non-null int64\n",
      "KO            14182 non-null int64\n",
      "MCD           14182 non-null int64\n",
      "MMM           14182 non-null int64\n",
      "MRK           14182 non-null int64\n",
      "MSFT          14182 non-null int64\n",
      "NKE           14182 non-null int64\n",
      "PFE           14182 non-null int64\n",
      "PG            14182 non-null int64\n",
      "T             14182 non-null int64\n",
      "TRV           14182 non-null int64\n",
      "UNH           14182 non-null int64\n",
      "UTX           14182 non-null int64\n",
      "V             14182 non-null int64\n",
      "VZ            14182 non-null int64\n",
      "WMT           14182 non-null int64\n",
      "XOM           14182 non-null int64\n",
      "dtypes: float64(7), int64(48), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #checking what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "sentiments = ['NUM_NEG', 'NUM_NEG1', 'NUM_NEG2', 'NUM_NEG3','NUM_NEU','NUM_NEU1','NUM_NEU2','NUM_NEU3','NUM_POS',\n",
    "              'NUM_POS1','NUM_POS2', 'NUM_POS3']\n",
    "for e in sentiments:\n",
    "    if e.endswith(\"1\"):\n",
    "        data[e+\"_PER\"] = data[e]/data['TW1']\n",
    "    elif e.endswith(\"2\"):\n",
    "        data[e+\"_PER\"] = data[e]/data['TW2']\n",
    "    elif e.endswith(\"3\"):\n",
    "        data[e+\"_PER\"] = data[e]/data['TW3']\n",
    "    else:\n",
    "        data[e+\"_PER\"] = data[e]/data['TW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummies for each day\n",
    "data['Date']= pd.to_datetime(data['Date'])\n",
    "data['day'] = data['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>LOW</th>\n",
       "      <th>NUM_NEG</th>\n",
       "      <th>NUM_NEU</th>\n",
       "      <th>NUM_POS</th>\n",
       "      <th>TW</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_POS1_PER</th>\n",
       "      <th>NUM_POS2_PER</th>\n",
       "      <th>NUM_POS3_PER</th>\n",
       "      <th>day_Friday</th>\n",
       "      <th>day_Monday</th>\n",
       "      <th>day_Saturday</th>\n",
       "      <th>day_Sunday</th>\n",
       "      <th>day_Thursday</th>\n",
       "      <th>day_Tuesday</th>\n",
       "      <th>day_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>77.24</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>75.96</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>76.28</td>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>74.64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>74.64</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Date   HIGH  CLOSE   OPEN    LOW  NUM_NEG  NUM_NEU  \\\n",
       "0           0 2013-06-04  77.24  76.02  76.50  75.96        2       12   \n",
       "1           1 2013-06-05  76.28  74.79  76.04  74.64        0        4   \n",
       "2           2 2013-06-06  76.25  76.24  74.75  74.64        1        9   \n",
       "3           3 2013-06-07  78.12  78.03  76.68  76.45        2        4   \n",
       "4           4 2013-06-08  78.12  78.03  76.68  76.45        0        3   \n",
       "\n",
       "   NUM_POS  TW      ...        NUM_POS1_PER  NUM_POS2_PER  NUM_POS3_PER  \\\n",
       "0        6  20      ...            0.090909      0.000000      0.000000   \n",
       "1        2   6      ...            0.300000      0.090909      0.000000   \n",
       "2        0  10      ...            0.333333      0.300000      0.090909   \n",
       "3       11  17      ...            0.000000      0.333333      0.300000   \n",
       "4        3   6      ...            0.647059      0.000000      0.333333   \n",
       "\n",
       "   day_Friday  day_Monday  day_Saturday  day_Sunday  day_Thursday  \\\n",
       "0           0           0             0           0             0   \n",
       "1           0           0             0           0             0   \n",
       "2           0           0             0           0             1   \n",
       "3           1           0             0           0             0   \n",
       "4           0           0             1           0             0   \n",
       "\n",
       "   day_Tuesday  day_Wednesday  \n",
       "0            1              0  \n",
       "1            0              1  \n",
       "2            0              0  \n",
       "3            0              0  \n",
       "4            0              0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.get_dummies(data, columns=['day'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NUM_NEG_PER', 'NUM_NEG1_PER', 'NUM_NEG2_PER', 'NUM_NEG3_PER',\n",
       "       'NUM_NEU_PER', 'NUM_NEU1_PER', 'NUM_NEU2_PER', 'NUM_NEU3_PER',\n",
       "       'NUM_POS_PER', 'NUM_POS1_PER', 'NUM_POS2_PER', 'NUM_POS3_PER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_null = data.columns[data.isnull().any()] # seeing where there might be a problem\n",
    "is_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14182 entries, 0 to 14181\n",
      "Data columns (total 12 columns):\n",
      "NUM_NEG_PER     14150 non-null float64\n",
      "NUM_NEG1_PER    14150 non-null float64\n",
      "NUM_NEG2_PER    14149 non-null float64\n",
      "NUM_NEG3_PER    14149 non-null float64\n",
      "NUM_NEU_PER     14150 non-null float64\n",
      "NUM_NEU1_PER    14150 non-null float64\n",
      "NUM_NEU2_PER    14149 non-null float64\n",
      "NUM_NEU3_PER    14149 non-null float64\n",
      "NUM_POS_PER     14150 non-null float64\n",
      "NUM_POS1_PER    14150 non-null float64\n",
      "NUM_POS2_PER    14149 non-null float64\n",
      "NUM_POS3_PER    14149 non-null float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "data[is_null].info() # about 30 missing for each, for whatever reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in is_null: #just fill them in with whatever is closest\n",
    "    data[e].fillna(data[e].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): # create the classes\n",
    "    if data.loc[i,\"CLOSE\"] > data.loc[i,\"OPEN\"]+.25:\n",
    "        data.loc[i,\"class\"] = 1 # gained by more than $.25\n",
    "    elif data.loc[i,\"CLOSE\"] < data.loc[i,'OPEN']-.25:\n",
    "        data.loc[i,\"class\"] = 2 # lost by more than $.25 \n",
    "    else:\n",
    "        data.loc[i,\"class\"] = 0 # minimal change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>Date</th>\n",
       "      <th>weekend</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.27</td>\n",
       "      <td>77.98</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.52</td>\n",
       "      <td>77.61</td>\n",
       "      <td>2013-06-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74.72</td>\n",
       "      <td>76.91</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75.21</td>\n",
       "      <td>74.46</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73.86</td>\n",
       "      <td>73.69</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>74.99</td>\n",
       "      <td>74.10</td>\n",
       "      <td>2013-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.24</td>\n",
       "      <td>74.87</td>\n",
       "      <td>2013-06-19</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72.95</td>\n",
       "      <td>73.76</td>\n",
       "      <td>2013-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72.03</td>\n",
       "      <td>72.57</td>\n",
       "      <td>2013-06-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73.23</td>\n",
       "      <td>72.63</td>\n",
       "      <td>2013-06-25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73.91</td>\n",
       "      <td>73.64</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75.14</td>\n",
       "      <td>74.46</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75.64</td>\n",
       "      <td>75.53</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74.62</td>\n",
       "      <td>75.43</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74.37</td>\n",
       "      <td>74.02</td>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14152</th>\n",
       "      <td>99.71</td>\n",
       "      <td>99.55</td>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14153</th>\n",
       "      <td>99.29</td>\n",
       "      <td>99.80</td>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14154</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14155</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14156</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14157</th>\n",
       "      <td>98.78</td>\n",
       "      <td>98.58</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14158</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.12</td>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>99.49</td>\n",
       "      <td>99.78</td>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14160</th>\n",
       "      <td>99.61</td>\n",
       "      <td>99.04</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14164</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>98.46</td>\n",
       "      <td>99.43</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14166</th>\n",
       "      <td>99.11</td>\n",
       "      <td>98.86</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>98.36</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14170</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>97.74</td>\n",
       "      <td>98.92</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14172</th>\n",
       "      <td>97.39</td>\n",
       "      <td>97.80</td>\n",
       "      <td>2014-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14173</th>\n",
       "      <td>96.82</td>\n",
       "      <td>97.38</td>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14174</th>\n",
       "      <td>97.01</td>\n",
       "      <td>96.32</td>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14176</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14178</th>\n",
       "      <td>96.28</td>\n",
       "      <td>95.73</td>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>97.43</td>\n",
       "      <td>96.23</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14180</th>\n",
       "      <td>97.08</td>\n",
       "      <td>97.83</td>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14181</th>\n",
       "      <td>96.62</td>\n",
       "      <td>97.15</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14182 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLOSE   OPEN       Date  weekend  class\n",
       "0      76.02  76.50 2013-06-04        0    2.0\n",
       "1      74.79  76.04 2013-06-05        0    2.0\n",
       "2      76.24  74.75 2013-06-06        0    1.0\n",
       "3      78.03  76.68 2013-06-07        0    1.0\n",
       "4      78.03  76.68 2013-06-08        1    1.0\n",
       "5      78.03  76.68 2013-06-09        1    1.0\n",
       "6      78.27  77.98 2013-06-10        0    1.0\n",
       "7      76.52  77.61 2013-06-11        0    2.0\n",
       "8      74.72  76.91 2013-06-12        0    2.0\n",
       "9      75.21  74.46 2013-06-13        0    1.0\n",
       "10     72.96  74.78 2013-06-14        0    2.0\n",
       "11     72.96  74.78 2013-06-15        1    2.0\n",
       "12     72.96  74.78 2013-06-16        1    2.0\n",
       "13     73.86  73.69 2013-06-17        0    0.0\n",
       "14     74.99  74.10 2013-06-18        0    1.0\n",
       "15     74.24  74.87 2013-06-19        0    2.0\n",
       "16     72.95  73.76 2013-06-20        0    2.0\n",
       "17     73.33  73.38 2013-06-21        0    0.0\n",
       "18     73.33  73.38 2013-06-22        1    0.0\n",
       "19     73.33  73.38 2013-06-23        1    0.0\n",
       "20     72.03  72.57 2013-06-24        0    2.0\n",
       "21     73.23  72.63 2013-06-25        0    1.0\n",
       "22     73.91  73.64 2013-06-26        0    1.0\n",
       "23     75.14  74.46 2013-06-27        0    1.0\n",
       "24     74.69  75.00 2013-06-28        0    2.0\n",
       "25     74.69  75.00 2013-06-29        1    2.0\n",
       "26     74.69  75.00 2013-06-30        1    2.0\n",
       "27     75.64  75.53 2013-07-01        0    0.0\n",
       "28     74.62  75.43 2013-07-02        0    2.0\n",
       "29     74.37  74.02 2013-07-03        0    1.0\n",
       "...      ...    ...        ...      ...    ...\n",
       "14152  99.71  99.55 2014-08-20        0    0.0\n",
       "14153  99.29  99.80 2014-08-21        0    2.0\n",
       "14154  98.50  98.90 2014-08-22        0    2.0\n",
       "14155  98.50  98.90 2014-08-23        1    2.0\n",
       "14156  98.50  98.90 2014-08-24        1    2.0\n",
       "14157  98.78  98.58 2014-08-25        0    0.0\n",
       "14158  99.65  99.12 2014-08-26        0    1.0\n",
       "14159  99.49  99.78 2014-08-27        0    2.0\n",
       "14160  99.61  99.04 2014-08-28        0    1.0\n",
       "14161  99.45  99.38 2014-08-29        0    0.0\n",
       "14162  99.45  99.38 2014-08-30        1    0.0\n",
       "14163  99.45  99.38 2014-08-31        1    0.0\n",
       "14164  99.45  99.38 2014-09-01        1    0.0\n",
       "14165  98.46  99.43 2014-09-02        0    2.0\n",
       "14166  99.11  98.86 2014-09-03        0    0.0\n",
       "14167  98.36  99.00 2014-09-04        0    2.0\n",
       "14168  99.19  98.74 2014-09-05        0    1.0\n",
       "14169  99.19  98.74 2014-09-06        1    1.0\n",
       "14170  99.19  98.74 2014-09-07        1    1.0\n",
       "14171  97.74  98.92 2014-09-08        0    2.0\n",
       "14172  97.39  97.80 2014-09-09        0    2.0\n",
       "14173  96.82  97.38 2014-09-10        0    2.0\n",
       "14174  97.01  96.32 2014-09-11        0    1.0\n",
       "14175  95.77  96.53 2014-09-12        0    2.0\n",
       "14176  95.77  96.53 2014-09-13        1    2.0\n",
       "14177  95.77  96.53 2014-09-14        1    2.0\n",
       "14178  96.28  95.73 2014-09-15        0    1.0\n",
       "14179  97.43  96.23 2014-09-16        0    1.0\n",
       "14180  97.08  97.83 2014-09-17        0    2.0\n",
       "14181  96.62  97.15 2014-09-18        0    2.0\n",
       "\n",
       "[14182 rows x 5 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"CLOSE\", \"OPEN\", \"Date\", \"weekend\",\"class\"]] #see how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>LOW</th>\n",
       "      <th>NUM_NEG</th>\n",
       "      <th>NUM_NEU</th>\n",
       "      <th>NUM_POS</th>\n",
       "      <th>TW</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_POS2_PER</th>\n",
       "      <th>NUM_POS3_PER</th>\n",
       "      <th>day_Friday</th>\n",
       "      <th>day_Monday</th>\n",
       "      <th>day_Saturday</th>\n",
       "      <th>day_Sunday</th>\n",
       "      <th>day_Thursday</th>\n",
       "      <th>day_Tuesday</th>\n",
       "      <th>day_Wednesday</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>77.24</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>75.96</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>76.28</td>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>74.64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>74.64</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>78.61</td>\n",
       "      <td>78.27</td>\n",
       "      <td>77.98</td>\n",
       "      <td>77.69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Date   HIGH  CLOSE   OPEN    LOW  NUM_NEG  NUM_NEU  \\\n",
       "0           0 2013-06-04  77.24  76.02  76.50  75.96        2       12   \n",
       "1           1 2013-06-05  76.28  74.79  76.04  74.64        0        4   \n",
       "2           2 2013-06-06  76.25  76.24  74.75  74.64        1        9   \n",
       "3           3 2013-06-07  78.12  78.03  76.68  76.45        2        4   \n",
       "6           6 2013-06-10  78.61  78.27  77.98  77.69        0        6   \n",
       "\n",
       "   NUM_POS  TW  ...    NUM_POS2_PER  NUM_POS3_PER  day_Friday  day_Monday  \\\n",
       "0        6  20  ...        0.000000      0.000000           0           0   \n",
       "1        2   6  ...        0.090909      0.000000           0           0   \n",
       "2        0  10  ...        0.300000      0.090909           0           0   \n",
       "3       11  17  ...        0.333333      0.300000           1           0   \n",
       "6        7  13  ...        0.500000      0.647059           0           1   \n",
       "\n",
       "   day_Saturday  day_Sunday  day_Thursday  day_Tuesday  day_Wednesday  class  \n",
       "0             0           0             0            1              0    2.0  \n",
       "1             0           0             0            0              1    2.0  \n",
       "2             0           0             1            0              0    1.0  \n",
       "3             0           0             0            0              0    1.0  \n",
       "6             0           0             0            0              0    1.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.loc[data.weekend==0]\n",
    "data.head() #drop out the weekend data since it doesn't really tell us anything and see if it worked (it did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.CLOSE # target\n",
    "target_class = data[\"class\"] # target for classifiers\n",
    "high = data.HIGH # other columns that we don't really need for now\n",
    "low = data.LOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(columns=['CLOSE', 'HIGH', 'LOW', 'Unnamed: 0', 'class', 'day_Saturday', 'day_Sunday']) # get rid of those ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nodate = data1.drop(columns='Date') # create a df without the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prev = data_nodate.drop(columns=['NUM_NEG', 'NUM_NEU', 'NUM_POS', 'NUM_NEG_PER', 'NUM_NEU_PER', 'NUM_POS_PER', \"TW\"])\n",
    "# create a df without anything for the day of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nopen_date = data_nodate.drop(columns='OPEN')\n",
    "data_nopen_prev = data_prev.drop(columns='OPEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn everything into floats so that scaler is happy\n",
    "\n",
    "data_nodate = pd.DataFrame(data_nodate, dtype='float')\n",
    "data_prev = pd.DataFrame(data_prev, dtype='float')\n",
    "data_nopen_date = pd.DataFrame(data_nopen_date, dtype='float')\n",
    "data_nopen_prev = pd.DataFrame(data_nopen_prev, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9832 entries, 0 to 14181\n",
      "Data columns (total 60 columns):\n",
      "weekend          9832 non-null float64\n",
      "NUM_NEG1         9832 non-null float64\n",
      "NUM_NEG2         9832 non-null float64\n",
      "NUM_NEG3         9832 non-null float64\n",
      "NUM_NEU1         9832 non-null float64\n",
      "NUM_NEU2         9832 non-null float64\n",
      "NUM_NEU3         9832 non-null float64\n",
      "NUM_POS1         9832 non-null float64\n",
      "NUM_POS2         9832 non-null float64\n",
      "NUM_POS3         9832 non-null float64\n",
      "TW1              9832 non-null float64\n",
      "TW2              9832 non-null float64\n",
      "TW3              9832 non-null float64\n",
      "CLOSE1           9832 non-null float64\n",
      "CLOSE2           9832 non-null float64\n",
      "CLOSE3           9832 non-null float64\n",
      "AXP              9832 non-null float64\n",
      "BA               9832 non-null float64\n",
      "CAT              9832 non-null float64\n",
      "CSCO             9832 non-null float64\n",
      "CVX              9832 non-null float64\n",
      "DD               9832 non-null float64\n",
      "DIS              9832 non-null float64\n",
      "GE               9832 non-null float64\n",
      "GS               9832 non-null float64\n",
      "HD               9832 non-null float64\n",
      "IBM              9832 non-null float64\n",
      "INTC             9832 non-null float64\n",
      "JNJ              9832 non-null float64\n",
      "JPM              9832 non-null float64\n",
      "KO               9832 non-null float64\n",
      "MCD              9832 non-null float64\n",
      "MMM              9832 non-null float64\n",
      "MRK              9832 non-null float64\n",
      "MSFT             9832 non-null float64\n",
      "NKE              9832 non-null float64\n",
      "PFE              9832 non-null float64\n",
      "PG               9832 non-null float64\n",
      "T                9832 non-null float64\n",
      "TRV              9832 non-null float64\n",
      "UNH              9832 non-null float64\n",
      "UTX              9832 non-null float64\n",
      "V                9832 non-null float64\n",
      "VZ               9832 non-null float64\n",
      "WMT              9832 non-null float64\n",
      "XOM              9832 non-null float64\n",
      "NUM_NEG1_PER     9832 non-null float64\n",
      "NUM_NEG2_PER     9832 non-null float64\n",
      "NUM_NEG3_PER     9832 non-null float64\n",
      "NUM_NEU1_PER     9832 non-null float64\n",
      "NUM_NEU2_PER     9832 non-null float64\n",
      "NUM_NEU3_PER     9832 non-null float64\n",
      "NUM_POS1_PER     9832 non-null float64\n",
      "NUM_POS2_PER     9832 non-null float64\n",
      "NUM_POS3_PER     9832 non-null float64\n",
      "day_Friday       9832 non-null float64\n",
      "day_Monday       9832 non-null float64\n",
      "day_Thursday     9832 non-null float64\n",
      "day_Tuesday      9832 non-null float64\n",
      "day_Wednesday    9832 non-null float64\n",
      "dtypes: float64(60)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "data_nopen_prev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is clean, we can try to run some different models on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #scale each of the three sets with open\n",
    "\n",
    "scaler.fit(data_nodate)\n",
    "scaled_df_noo = scaler.transform(data_nodate)\n",
    "\n",
    "scaler.fit(data_prev)\n",
    "scaled_prevo = scaler.transform(data_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into test and training sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(scaled_df_noo, target, test_size=.2, random_state = 11)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(scaled_prevo, target, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curve(clf, \"Learning Curve\", X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6975927006156463\n",
      "Test MSE: 0.6147122494261432\n"
     ]
    }
   ],
   "source": [
    "# elastic net without dates\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train1, y_train1)\n",
    "train_predictions = clf.predict(X_train1)\n",
    "test_predictions = clf.predict(X_test1)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train1, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test1, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM_NEG', -0.0),\n",
       " ('NUM_NEU', -0.0),\n",
       " ('NUM_POS', 0.0),\n",
       " ('TW', -0.0),\n",
       " ('weekend', 0.0),\n",
       " ('NUM_NEG1', 0.0),\n",
       " ('NUM_NEG2', 0.0),\n",
       " ('NUM_NEG3', 0.0),\n",
       " ('NUM_NEU1', -0.0),\n",
       " ('NUM_NEU2', -0.0),\n",
       " ('NUM_NEU3', -0.0),\n",
       " ('NUM_POS1', 0.0),\n",
       " ('NUM_POS2', 0.0),\n",
       " ('NUM_POS3', 0.0),\n",
       " ('TW1', -0.0),\n",
       " ('TW2', 0.0),\n",
       " ('TW3', -0.0),\n",
       " ('CLOSE2', 0.0),\n",
       " ('AXP', -0.0),\n",
       " ('BA', 0.0),\n",
       " ('CAT', 0.0),\n",
       " ('CSCO', -0.0),\n",
       " ('CVX', 0.0),\n",
       " ('DD', -0.0),\n",
       " ('DIS', -0.0),\n",
       " ('GE', -0.0),\n",
       " ('GS', 0.0),\n",
       " ('HD', -0.0),\n",
       " ('IBM', 0.0),\n",
       " ('INTC', -0.0),\n",
       " ('JNJ', 0.0),\n",
       " ('JPM', -0.0),\n",
       " ('KO', -0.0),\n",
       " ('MCD', 0.0),\n",
       " ('MMM', 0.0),\n",
       " ('MRK', -0.0),\n",
       " ('MSFT', -0.0),\n",
       " ('NKE', -0.0),\n",
       " ('PFE', -0.0),\n",
       " ('PG', -0.0),\n",
       " ('T', -0.0),\n",
       " ('TRV', 0.0),\n",
       " ('UNH', 0.0),\n",
       " ('UTX', -0.0),\n",
       " ('V', 0.0),\n",
       " ('VZ', -0.0),\n",
       " ('WMT', -0.0),\n",
       " ('XOM', 0.0),\n",
       " ('NUM_NEG1_PER', -0.0),\n",
       " ('NUM_NEG2_PER', 0.0),\n",
       " ('NUM_NEG3_PER', 0.0),\n",
       " ('NUM_NEU_PER', -0.0),\n",
       " ('NUM_NEU1_PER', 0.0),\n",
       " ('NUM_NEU2_PER', -0.0),\n",
       " ('NUM_NEU3_PER', -0.0),\n",
       " ('NUM_POS_PER', 0.0),\n",
       " ('NUM_POS1_PER', -0.0),\n",
       " ('NUM_POS2_PER', 0.0),\n",
       " ('NUM_POS3_PER', 0.0),\n",
       " ('day_Friday', 0.0),\n",
       " ('day_Monday', 0.0),\n",
       " ('day_Thursday', -0.0),\n",
       " ('day_Tuesday', -0.0),\n",
       " ('day_Wednesday', 0.0),\n",
       " ('CLOSE3', 0.00010518804593296828),\n",
       " ('CLOSE1', 0.0009781409480861133),\n",
       " ('NUM_NEG_PER', -0.017464415453367823),\n",
       " ('OPEN', 45.74861085962495)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above\n",
    "sorted(list(zip(data_nodate, clf.coef_)), key=lambda x: abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.7016509280024095\n",
      "Test MSE: 0.6184034738226846\n"
     ]
    }
   ],
   "source": [
    "# elastic net without today's data\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train2, y_train2)\n",
    "train_predictions = clf.predict(X_train2)\n",
    "test_predictions = clf.predict(X_test2)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train2, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test2, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weekend', 0.0),\n",
       " ('NUM_NEG1', -0.0),\n",
       " ('NUM_NEG2', 0.0),\n",
       " ('NUM_NEG3', -0.0),\n",
       " ('NUM_NEU1', -0.0),\n",
       " ('NUM_NEU2', -0.0),\n",
       " ('NUM_NEU3', -0.0),\n",
       " ('NUM_POS1', 0.0),\n",
       " ('NUM_POS2', 0.0),\n",
       " ('NUM_POS3', 0.0),\n",
       " ('TW1', -0.0),\n",
       " ('TW2', -0.0),\n",
       " ('TW3', -0.0),\n",
       " ('CLOSE2', 0.0),\n",
       " ('AXP', -0.0),\n",
       " ('BA', 0.0),\n",
       " ('CAT', 0.0),\n",
       " ('CSCO', -0.0),\n",
       " ('CVX', 0.0),\n",
       " ('DD', -0.0),\n",
       " ('DIS', -0.0),\n",
       " ('GE', -0.0),\n",
       " ('GS', 0.0),\n",
       " ('HD', -0.0),\n",
       " ('IBM', 0.0),\n",
       " ('INTC', -0.0),\n",
       " ('JNJ', 0.0),\n",
       " ('JPM', -0.0),\n",
       " ('KO', -0.0),\n",
       " ('MCD', 0.0),\n",
       " ('MMM', 0.0),\n",
       " ('MRK', -0.0),\n",
       " ('MSFT', -0.0),\n",
       " ('NKE', -0.0),\n",
       " ('PFE', -0.0),\n",
       " ('PG', -0.0),\n",
       " ('T', -0.0),\n",
       " ('TRV', 0.0),\n",
       " ('UNH', 0.0),\n",
       " ('UTX', -0.0),\n",
       " ('V', 0.0),\n",
       " ('VZ', -0.0),\n",
       " ('WMT', -0.0),\n",
       " ('XOM', 0.0),\n",
       " ('NUM_NEG1_PER', -0.0),\n",
       " ('NUM_NEG2_PER', 0.0),\n",
       " ('NUM_NEG3_PER', 0.0),\n",
       " ('NUM_NEU1_PER', 0.0),\n",
       " ('NUM_NEU2_PER', -0.0),\n",
       " ('NUM_NEU3_PER', -0.0),\n",
       " ('NUM_POS1_PER', 0.0),\n",
       " ('NUM_POS2_PER', 0.0),\n",
       " ('NUM_POS3_PER', 0.0),\n",
       " ('day_Friday', 0.0),\n",
       " ('day_Monday', 0.0),\n",
       " ('day_Thursday', -0.0),\n",
       " ('day_Tuesday', -0.0),\n",
       " ('day_Wednesday', 0.0),\n",
       " ('CLOSE3', 5.1750993891675995e-05),\n",
       " ('CLOSE1', 0.0009427073220183619),\n",
       " ('OPEN', 45.74740771063074)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(data_prev, clf.coef_)), key=lambda x: abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data wihtout open\n",
    "scaler.fit(data_nopen_date)\n",
    "scaled_df_non = scaler.transform(data_nopen_date)\n",
    "\n",
    "scaler.fit(data_nopen_prev)\n",
    "scaled_prevn = scaler.transform(data_nopen_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training sets\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(scaled_df_non, target, test_size=.2, random_state = 11)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(scaled_prevn, target, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.9258320276420248\n",
      "Test MSE: 0.9284107449636377\n",
      "[('NUM_NEG', -0.0), ('NUM_NEU', -0.0), ('NUM_POS', 0.0), ('TW', -0.0), ('weekend', 0.0), ('NUM_NEG1', -0.0), ('NUM_NEG2', 0.0), ('NUM_NEG3', 0.0), ('NUM_NEU1', -0.0), ('NUM_NEU2', -0.0), ('NUM_NEU3', -0.0), ('NUM_POS1', -0.0), ('NUM_POS2', 0.0), ('NUM_POS3', 0.0), ('TW1', -0.0), ('TW2', -0.0), ('TW3', -0.0), ('AXP', -0.0), ('BA', 0.0), ('CAT', 0.0), ('CSCO', -0.0), ('CVX', 0.0), ('DD', -0.0), ('DIS', -0.0), ('GE', -0.0), ('GS', 0.0), ('HD', -0.0), ('IBM', 0.0), ('INTC', -0.0), ('JNJ', 0.0), ('JPM', 0.0), ('KO', -0.0), ('MCD', 0.0), ('MMM', 0.0), ('MRK', -0.0), ('MSFT', -0.0), ('NKE', -0.0), ('PFE', -0.0), ('PG', -0.0), ('T', -0.0), ('TRV', 0.0), ('UNH', -0.0), ('UTX', -0.0), ('V', 0.0), ('VZ', -0.0), ('WMT', 0.0), ('XOM', -0.0), ('NUM_NEG1_PER', 0.0), ('NUM_NEG2_PER', 0.0), ('NUM_NEG3_PER', 0.0), ('NUM_NEU_PER', -0.0), ('NUM_NEU1_PER', 0.0), ('NUM_NEU2_PER', -0.0), ('NUM_NEU3_PER', -0.0), ('NUM_POS1_PER', -0.0), ('NUM_POS2_PER', 0.0), ('NUM_POS3_PER', 0.0), ('day_Friday', 0.0), ('day_Monday', 0.0), ('day_Thursday', -0.0), ('day_Tuesday', 0.0), ('day_Wednesday', -0.0), ('CLOSE3', 0.0012846336047228862), ('CLOSE2', 0.003066900537554512), ('NUM_POS_PER', 0.05358036803609073), ('NUM_NEG_PER', -0.09935676229399229), ('CLOSE1', 45.750913596246946)]\n"
     ]
    }
   ],
   "source": [
    "# Elastic net with no dates\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train4, y_train4)\n",
    "train_predictions = clf.predict(X_train4)\n",
    "test_predictions = clf.predict(X_test4)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train4, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test4, test_predictions)))\n",
    "print(sorted(list(zip(data_nopen_date, clf.coef_)), key=lambda x: abs(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.9726292029699234\n",
      "Test MSE: 0.9722017680023588\n",
      "[('weekend', 0.0), ('NUM_NEG1', -0.0), ('NUM_NEG2', -0.0), ('NUM_NEG3', -0.0), ('NUM_NEU1', -0.0), ('NUM_NEU2', -0.0), ('NUM_NEU3', -0.0), ('NUM_POS1', 0.0), ('NUM_POS2', 0.0), ('NUM_POS3', 0.0), ('TW1', -0.0), ('TW2', -0.0), ('TW3', -0.0), ('AXP', 0.0), ('BA', 0.0), ('CAT', 0.0), ('CSCO', -0.0), ('CVX', 0.0), ('DD', -0.0), ('DIS', 0.0), ('GE', -0.0), ('GS', 0.0), ('HD', 0.0), ('IBM', 0.0), ('INTC', -0.0), ('JNJ', 0.0), ('JPM', -0.0), ('KO', -0.0), ('MCD', -0.0), ('MMM', 0.0), ('MRK', -0.0), ('MSFT', -0.0), ('NKE', 0.0), ('PFE', -0.0), ('PG', -0.0), ('T', -0.0), ('TRV', 0.0), ('UNH', 0.0), ('UTX', -0.0), ('V', 0.0), ('VZ', -0.0), ('WMT', -0.0), ('XOM', -0.0), ('NUM_NEG1_PER', -0.0), ('NUM_NEG2_PER', -0.0), ('NUM_NEG3_PER', 0.0), ('NUM_NEU1_PER', 0.0), ('NUM_NEU2_PER', -0.0), ('NUM_NEU3_PER', -0.0), ('NUM_POS1_PER', 0.0), ('NUM_POS2_PER', 0.0), ('NUM_POS3_PER', 0.0), ('day_Friday', 0.0), ('day_Monday', 0.0), ('day_Thursday', -0.0), ('day_Tuesday', 0.0), ('day_Wednesday', -0.0), ('CLOSE3', 0.00085934530188519), ('CLOSE2', 0.0011311188634523632), ('CLOSE1', 45.74671760703851)]\n"
     ]
    }
   ],
   "source": [
    "# elastic net without anything from the day being predicted\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train5, y_train5)\n",
    "train_predictions = clf.predict(X_train5)\n",
    "test_predictions = clf.predict(X_test5)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train5, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test5, test_predictions)))\n",
    "print(sorted(list(zip(data_nopen_prev, clf.coef_)), key=lambda x: abs(x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, it isn't very interesting to use the data to predict future prices because it ends up that basically the only thing you want to know is what the opening price/yesterday's price is, and then how people were tweeting the day of (possibly after closing). So instead we'll try to predict if tweets can forecast if the stock is going to go up or down. The \"previous\" data is the most important sort here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #Nearest Neighbors\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, GaussianNB # different Bayesian models\n",
    "from sklearn.svm import SVC #support vector machine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier #ensemble models\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV #to do cross validation\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error #different ways of scoring\n",
    "from sklearn.metrics import classification_report # classification report\n",
    "from sklearn.metrics import confusion_matrix # confusion matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training sets from the previous day data (with and without OPEN)\n",
    "X_traincO, X_testcO, y_traincO, y_testcO = train_test_split(scaled_prevo, target_class, test_size=.2, random_state = 11)\n",
    "X_trainc, X_testc, y_trainc, y_testc = train_test_split(scaled_prevn, target_class, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n",
      "Train F1: [0.65745856 0.49035235 0.41751746]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.65      0.58       801\n",
      "         1.0       0.40      0.38      0.39       630\n",
      "         2.0       0.32      0.22      0.26       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.41      0.42      0.41      1967\n",
      "weighted avg       0.43      0.45      0.43      1967\n",
      "\n",
      "Train Accuracy: 0.5500317863954227\tTest accuracy: 0.44636502287747837\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors with open\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_traincO, y_traincO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_traincO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_traincO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testcO)\n",
    "print(classification_report(y_testcO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_traincO, y_pred_train),\n",
    "                                                     accuracy_score(y_testcO, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[518, 178, 105],\n",
       "       [247, 242, 141],\n",
       "       [228, 190, 118]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matric to evaluate performance\n",
    "confusion_matrix(y_testcO, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n",
      "Train F1: [0.65819638 0.49245599 0.41861716]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.65      0.58       801\n",
      "         1.0       0.40      0.39      0.39       630\n",
      "         2.0       0.32      0.22      0.26       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.41      0.42      0.41      1967\n",
      "weighted avg       0.43      0.45      0.43      1967\n",
      "\n",
      "Train Accuracy: 0.5513032422123331\tTest accuracy: 0.44687341128622265\n",
      "[[517 178 106]\n",
      " [243 245 142]\n",
      " [228 191 117]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors without open\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainc, y_trainc)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainc)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainc, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testc)\n",
    "print(classification_report(y_testc, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainc, y_pred_train),\n",
    "                                                     accuracy_score(y_testc, y_pred_test)))\n",
    "print(confusion_matrix(y_testc, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first of all this model is overfitting, but not too much. Removing \"OPEN\" made it only marginally better (talking like 4 more in the second class and 1 less in the other classes) so that indicates that OPEN is not a driving force for this problem (unlike the basic prediction problem). Secondly, it seems to mostly put things in the first class (no major change) which works okay but not great. It is really bad at predicting a drop in prices, so I'm not sure what is going on there, except that it probaly trained itself to mostly put things in the first class. I'll try a random forest, since we can get feature importances from that which may give valuable information about what variables to keep and what ones to drop so that we stop overfitting the nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'class_weight': 'balanced', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'n_estimators': 100, 'random_state': 9}\n",
      "Train F1: [0.63246959 0.68599222 0.67032744]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.50      0.56       801\n",
      "         1.0       0.39      0.44      0.42       630\n",
      "         2.0       0.32      0.38      0.35       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.45      0.44      0.44      1967\n",
      "weighted avg       0.48      0.45      0.46      1967\n",
      "\n",
      "Train Accuracy: 0.6617927527018436\tTest accuracy: 0.4489069649211998\n",
      "[[398 210 193]\n",
      " [104 279 247]\n",
      " [109 221 206]]\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with Open\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_traincO, y_traincO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_traincO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_traincO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testcO)\n",
    "print(classification_report(y_testcO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_traincO, y_pred_train),\n",
    "                                                     accuracy_score(y_testcO, y_pred_test)))\n",
    "print(confusion_matrix(y_testcO, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcb = RandomForestClassifier(n_estimators = 100, max_features='sqrt', min_samples_leaf=9, max_depth\n",
    "                             = 11, class_weight='balanced', random_state=9)\n",
    "rfcb.fit(X_traincO, y_traincO)\n",
    "feature_imp_rfc1 = sorted(list(zip(data_prev, rfcb.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 9, 'n_estimators': 20, 'random_state': 9}\n",
      "Train F1: [0.58290386 0.51775148 0.4600639 ]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.50      0.57       801\n",
      "         1.0       0.39      0.46      0.42       630\n",
      "         2.0       0.30      0.35      0.32       536\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      1967\n",
      "   macro avg       0.45      0.44      0.44      1967\n",
      "weighted avg       0.48      0.44      0.45      1967\n",
      "\n",
      "Train Accuracy: 0.5238397965670692\tTest accuracy: 0.44483985765124556\n",
      "[[398 212 191]\n",
      " [ 96 290 244]\n",
      " [ 99 250 187]]\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier without Open\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainc, y_trainc)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainc)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainc, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testc)\n",
    "print(classification_report(y_testc, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainc, y_pred_train),\n",
    "                                                     accuracy_score(y_testc, y_pred_test)))\n",
    "print(confusion_matrix(y_testc, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcb2 = RandomForestClassifier(class_weight= 'balanced', max_depth= 7, max_features= 'log2', min_samples_leaf= 9, \n",
    "                               n_estimators= 20, random_state= 9)\n",
    "rfcb2.fit(X_trainc, y_trainc)\n",
    "feature_imp_rfc2 = sorted(list(zip(data_nopen_prev, rfcb2.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now use an old set of functions I wrote to get plot out the most important features and then decide how to engineer from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_extract(dic):\n",
    "    y = pd.DataFrame.from_dict(dic, orient='index') #turns the dictionary into a data frame\n",
    "    y = y.index # list of the names in the dataframe\n",
    "    return y\n",
    "\n",
    "def feature_extract(data_frame, feature_importances, sensitivity): # function to extract a list of features above a given sensitivty\n",
    "    coef_dict = dict((zip(data_frame, feature_importances))) #creates a dictionary from the model's feature importance\n",
    "    coef_list = {} # another dictionary\n",
    "    for key in coef_dict: # runs through the zipped dictionary \n",
    "        x = coef_dict.get(key) # extracts value for the key\n",
    "        if abs(x) > sensitivity:  # if the absolute value is bigger than the sensitivity\n",
    "            coef_list[key] = x # adds a new entry to the other dictionary \n",
    "        else: # if the coefficient isn't big enough\n",
    "            pass # move to the next key\n",
    "    coef_list = key_extract(coef_list) # uses a previous function I wrote to make a list of the names of those coeff\n",
    "    return coef_list # returns that list\n",
    "\n",
    "def best_feature_dict(list_, features_imp): #creates a dictionary from a list of tuples using another list of names\n",
    "    y = {}\n",
    "    for e in list_:\n",
    "        y[e] = dict(features_imp).get(e)\n",
    "    return y\n",
    "\n",
    "def best_feature_plot(list_, features_imp, ticks=90): #plots the features importances\n",
    "    y = best_feature_dict(list_, features_imp)\n",
    "    plt.bar(y.keys(),y.values())\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xticks(rotation=ticks)\n",
    "    plt.ylabel(\"Percent Used\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "def features_full(data_frame, feature_importances, sensitivity): #combines these functions into one nice one\n",
    "    x = feature_extract(data_frame, feature_importances, sensitivity)\n",
    "    z = sorted(list(zip(data_frame, feature_importances)), key=lambda x: x[1], reverse=True)\n",
    "    y = best_feature_plot(x, z)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_feat1, best_featplt1 = features_full(data_prev, rfcb.feature_importances_, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_feat2, best_featplt2 = features_full(data_nopen_prev,rfcb2.feature_importances_, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiments do play a role in how these get classified, (though there is some weirdness because of the low number of estimators), however they are overshadowed by company level dummies and in the no-OPEN model, prior closing prices. Next, we'll look at correlations between these higher importance features and then maybe mess with the data set a bit more to get a less overfitting k-nearest neighbors model (since that one is still working the best). Might try and SVM too, since lower amounts of features helps a lot with that. Having OPEN doesn't make a huge difference on the final outcome (makes it more predictive of stock rises at the expense of predicting stock drops), but it does greatly change the feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_extract(var, sensitivity): # definine a function that will tell me where there is high correlation\n",
    "    y = dict() #the plan is to get a dictionary that gives me the name and value\n",
    "    count = 0 # set up the counter\n",
    "    for e in var:\n",
    "        if abs(e)<sensitivity: #most common is lower correlation so I'll get rid of those first\n",
    "            count = count + 1 #move to the next one\n",
    "        elif abs(e)==1: # get rid of perfect correlation because that isn't very interesting\n",
    "            count = count + 1 #\n",
    "        else: \n",
    "            x = var.index[count] #extract the name from the series\n",
    "            y[x] = e #key: index, value: correlation\n",
    "            count = count + 1 # move to the next one\n",
    "    return y \n",
    "\n",
    "def i_corr_extract(list_corr, var, sensitivity): #for doing a correlation extract except iterated\n",
    "    for x in list_corr:\n",
    "        print(x)\n",
    "        print(corr_extract(var[x], sensitivity))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN\n",
      "{'CLOSE1': 0.9999240565411533, 'CLOSE2': 0.9997489786275865, 'CLOSE3': 0.9996257383812366}\n",
      "\n",
      "NUM_NEG1\n",
      "{'NUM_NEG2': 0.40072841075456983, 'NUM_NEU1': 0.4540088375986588, 'NUM_POS1': 0.30752673486346693, 'TW1': 0.584803115922343, 'NUM_NEG1_PER': 0.4612739230162242}\n",
      "\n",
      "NUM_NEG2\n",
      "{'NUM_NEG1': 0.40072841075456983, 'NUM_NEG3': 0.387206927586199, 'NUM_NEU2': 0.4623410762765261, 'NUM_POS2': 0.3071868598610671, 'TW2': 0.5793869416725591, 'NUM_NEG2_PER': 0.42461473067175104}\n",
      "\n",
      "NUM_NEG3\n",
      "{'NUM_NEG2': 0.387206927586199, 'NUM_NEU3': 0.4766778528103975, 'NUM_POS3': 0.30377998074337137, 'TW3': 0.6029951376875174, 'NUM_NEG3_PER': 0.39192386739009266}\n",
      "\n",
      "NUM_NEU1\n",
      "{'NUM_NEG1': 0.4540088375986588, 'NUM_NEU2': 0.5328602666418161, 'NUM_NEU3': 0.3239130478807166, 'NUM_POS1': 0.5071520464052924, 'NUM_POS2': 0.34792113249215706, 'TW1': 0.9601406667664477, 'TW2': 0.5375441563927669, 'TW3': 0.30425833237783845}\n",
      "\n",
      "NUM_NEU2\n",
      "{'NUM_NEG2': 0.4623410762765261, 'NUM_NEU1': 0.5328602666418161, 'NUM_NEU3': 0.5000011821424186, 'NUM_POS2': 0.4763893811395791, 'TW1': 0.5132559345595629, 'TW2': 0.9611576921349934, 'TW3': 0.4801772287308318}\n",
      "\n",
      "NUM_NEU3\n",
      "{'NUM_NEG3': 0.4766778528103975, 'NUM_NEU1': 0.3239130478807166, 'NUM_NEU2': 0.5000011821424186, 'NUM_POS3': 0.5128872634012903, 'TW1': 0.30499975090728154, 'TW2': 0.48010317956061843, 'TW3': 0.9579456706224859}\n",
      "\n",
      "NUM_POS1\n",
      "{'NUM_NEG1': 0.30752673486346693, 'NUM_NEU1': 0.5071520464052924, 'NUM_POS2': 0.3409450236473794, 'TW1': 0.6935626863861732, 'TW2': 0.3247507710761385, 'NUM_POS1_PER': 0.33404868668962123}\n",
      "\n",
      "NUM_POS2\n",
      "{'NUM_NEG2': 0.3071868598610671, 'NUM_NEU1': 0.34792113249215706, 'NUM_NEU2': 0.4763893811395791, 'NUM_POS1': 0.3409450236473794, 'TW1': 0.37749103878667484, 'TW2': 0.673954586761564, 'NUM_POS2_PER': 0.3122505426317363}\n",
      "\n",
      "NUM_POS3\n",
      "{'NUM_NEG3': 0.30377998074337137, 'NUM_NEU3': 0.5128872634012903, 'TW2': 0.3121728412858614, 'TW3': 0.7025558944803271}\n",
      "\n",
      "TW1\n",
      "{'NUM_NEG1': 0.584803115922343, 'NUM_NEU1': 0.9601406667664477, 'NUM_NEU2': 0.5132559345595629, 'NUM_NEU3': 0.30499975090728154, 'NUM_POS1': 0.6935626863861732, 'NUM_POS2': 0.37749103878667484, 'TW2': 0.5366253653974549}\n",
      "\n",
      "TW2\n",
      "{'NUM_NEG2': 0.5793869416725591, 'NUM_NEU1': 0.5375441563927669, 'NUM_NEU2': 0.9611576921349934, 'NUM_NEU3': 0.48010317956061843, 'NUM_POS1': 0.3247507710761385, 'NUM_POS2': 0.673954586761564, 'NUM_POS3': 0.3121728412858614, 'TW1': 0.5366253653974549, 'TW3': 0.4790832476878278}\n",
      "\n",
      "TW3\n",
      "{'NUM_NEG3': 0.6029951376875174, 'NUM_NEU1': 0.30425833237783845, 'NUM_NEU2': 0.4801772287308318, 'NUM_NEU3': 0.9579456706224859, 'NUM_POS3': 0.7025558944803271, 'TW2': 0.4790832476878278}\n",
      "\n",
      "CLOSE1\n",
      "{'OPEN': 0.9999240565411533, 'CLOSE2': 0.9998198732117823, 'CLOSE3': 0.999701325145199}\n",
      "\n",
      "CLOSE2\n",
      "{'OPEN': 0.9997489786275865, 'CLOSE1': 0.9998198732117823, 'CLOSE3': 0.999875550815534}\n",
      "\n",
      "CLOSE3\n",
      "{'OPEN': 0.9996257383812366, 'CLOSE1': 0.999701325145199, 'CLOSE2': 0.999875550815534}\n",
      "\n",
      "CSCO\n",
      "{}\n",
      "\n",
      "GE\n",
      "{}\n",
      "\n",
      "NUM_NEG1_PER\n",
      "{'NUM_NEG1': 0.4612739230162242, 'NUM_NEG2_PER': 0.3237776618251944, 'NUM_NEU1_PER': -0.4913306137047581}\n",
      "\n",
      "NUM_NEG2_PER\n",
      "{'NUM_NEG2': 0.42461473067175104, 'NUM_NEG1_PER': 0.3237776618251944, 'NUM_NEG3_PER': 0.3167843139913862, 'NUM_NEU2_PER': -0.49418765420491867}\n",
      "\n",
      "NUM_NEG3_PER\n",
      "{'NUM_NEG3': 0.39192386739009266, 'NUM_NEG2_PER': 0.3167843139913862, 'NUM_NEU3_PER': -0.4916131678306075}\n",
      "\n",
      "NUM_NEU1_PER\n",
      "{'NUM_NEG1_PER': -0.4913306137047581, 'NUM_POS1_PER': -0.7797080980770543}\n",
      "\n",
      "NUM_NEU2_PER\n",
      "{'NUM_NEG2_PER': -0.49418765420491867, 'NUM_POS2_PER': -0.7900573957968738}\n",
      "\n",
      "NUM_NEU3_PER\n",
      "{'NUM_NEG3_PER': -0.4916131678306075, 'NUM_POS3_PER': -0.7922883877589932}\n",
      "\n",
      "NUM_POS1_PER\n",
      "{'NUM_POS1': 0.33404868668962123, 'NUM_NEU1_PER': -0.7797080980770543}\n",
      "\n",
      "NUM_POS2_PER\n",
      "{'NUM_POS2': 0.3122505426317363, 'NUM_NEU2_PER': -0.7900573957968738}\n",
      "\n",
      "NUM_POS3_PER\n",
      "{'NUM_NEU3_PER': -0.7922883877589932}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_corr = data_prev[best_feat2].corr()\n",
    "i_corr_extract(best_feat2, feature_corr, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these correlations are quite obvious. Percentages are correlated with the number said that day and the number of any type of tweet on a given day is correlated with the other numbers. I might just drop all the numbers and reduce down to a pure percentage model, even though the correlation isn't super strong. The pure number of tweets on a given day is not correlated with the percentages though, so I think I'll leave those in as a sort of control. \n",
    "\n",
    "Unsurprisingly, the closing prices are very very very correlated with each other. I think I'll drop the numbers and then re-run the model to see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_prev = []\n",
    "for e in sentiments:\n",
    "    if e.endswith('1'):\n",
    "        sentiments_prev.append(e)\n",
    "    elif e.endswith('2'):\n",
    "        sentiments_prev.append(e)\n",
    "    elif e.endswith('3'):\n",
    "        sentiments_prev.append(e)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prev_per = data_prev.drop(columns=sentiments_prev)\n",
    "data_noprev_per = data_nopen_prev.drop(columns=sentiments_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(data_prev_per)\n",
    "scaled_prevperO = scaler.transform(data_prev_per)\n",
    "\n",
    "scaler.fit(data_noprev_per)\n",
    "scaled_prevper = scaler.transform(data_noprev_per)\n",
    "\n",
    "X_trainPO, X_testPO, y_trainPO, y_testPO = train_test_split(scaled_prevperO, target_class, test_size=.2, random_state = 11)\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(scaled_prevper, target_class, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n",
      "Train F1: [0.65829423 0.49152188 0.41003507]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.64      0.58       801\n",
      "         1.0       0.40      0.40      0.40       630\n",
      "         2.0       0.30      0.21      0.25       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.41      0.42      0.41      1967\n",
      "weighted avg       0.43      0.45      0.43      1967\n",
      "\n",
      "Train Accuracy: 0.5491417673235856\tTest accuracy: 0.44534824605998985\n",
      "[[511 175 115]\n",
      " [235 252 143]\n",
      " [220 203 113]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors with open raw numbers dropped\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainPO, y_trainPO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainPO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainPO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testPO)\n",
    "print(classification_report(y_testPO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainPO, y_pred_train),\n",
    "                                                     accuracy_score(y_testPO, y_pred_test)))\n",
    "print(confusion_matrix(y_testPO, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 1, 'weights': 'uniform'}\n",
      "Train F1: [0.66867141 0.49181722 0.40064707]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.66      0.59       801\n",
      "         1.0       0.40      0.38      0.39       630\n",
      "         2.0       0.30      0.21      0.24       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.41      0.42      0.41      1967\n",
      "weighted avg       0.43      0.45      0.43      1967\n",
      "\n",
      "Train Accuracy: 0.5525746980292435\tTest accuracy: 0.44687341128622265\n",
      "[[528 164 109]\n",
      " [239 241 150]\n",
      " [226 200 110]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors without open raw numbers dropped\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainP, y_trainP)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainP)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainP, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testP)\n",
    "print(classification_report(y_testP, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainP, y_pred_train),\n",
    "                                                     accuracy_score(y_testP, y_pred_test)))\n",
    "print(confusion_matrix(y_testP, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'class_weight': 'balanced_subsample', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'n_estimators': 20, 'random_state': 9}\n",
      "Train F1: [0.61796365 0.59518167 0.56691338]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.50      0.57       801\n",
      "         1.0       0.37      0.38      0.37       630\n",
      "         2.0       0.28      0.37      0.32       536\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1967\n",
      "   macro avg       0.43      0.42      0.42      1967\n",
      "weighted avg       0.46      0.43      0.44      1967\n",
      "\n",
      "Train Accuracy: 0.5944055944055944\tTest accuracy: 0.42653787493645146\n",
      "[[404 167 230]\n",
      " [115 237 278]\n",
      " [105 233 198]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest no numbers with open\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainPO, y_trainPO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainPO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainPO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testPO)\n",
    "print(classification_report(y_testPO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainPO, y_pred_train),\n",
    "                                                     accuracy_score(y_testPO, y_pred_test)))\n",
    "print(confusion_matrix(y_testPO, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'class_weight': 'balanced', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 50, 'random_state': 9}\n",
      "Train F1: [0.62157867 0.62450593 0.59612958]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.51      0.58       801\n",
      "         1.0       0.40      0.46      0.43       630\n",
      "         2.0       0.31      0.35      0.33       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.46      0.44      0.45      1967\n",
      "weighted avg       0.48      0.45      0.46      1967\n",
      "\n",
      "Train Accuracy: 0.6148760330578512\tTest accuracy: 0.45348246059989833\n",
      "[[410 196 195]\n",
      " [106 292 232]\n",
      " [109 237 190]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest, raw numbers dropped\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainP, y_trainP)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainP)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainP, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testP)\n",
    "print(classification_report(y_testP, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainP, y_pred_train),\n",
    "                                                     accuracy_score(y_testP, y_pred_test)))\n",
    "print(confusion_matrix(y_testP, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=9, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=None, oob_score=False, random_state=9,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcbp = RandomForestClassifier(class_weight= 'balanced', max_depth= 9, max_features= 'sqrt', min_samples_leaf= 3, \n",
    "                               n_estimators= 50, random_state= 9)\n",
    "rfcbp.fit(X_trainP, y_trainP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_featp, best_featpltp = features_full(data_noprev_per,rfcbp.feature_importances_, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbors seems to be working by putting everything in the \"no change\" category, and does this even more when removing \"OPEN\" which also makes it put even more in there (slightly increasing the over all accuracy, but probably not enough to be worth it). \n",
    "\n",
    "The random forests (which for whatever reason, don't like lots of estimators) were interesting. They're much worse at putting \"no change\" in the right box, but are much better with the other two cateories, which is probably a good thing but it depends on what you want to do. Also, dropping the raw numbers and keeping \"OPEN\" makes the forest much worse than dropping the numbers and OPEN (which is currently the best model). This final model likes the sentiments more than when there is numbers. \n",
    "\n",
    "Another option for narrowing down the features list (and making this a bit less overfitting in the long run) is to use industries instead of dummies for each company. We used [this website](https://www.thestreet.com) to determine which companies were classified into which industries. Only two, United Health Group and du Pont had no comparable groups, so we just left those dummies as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial = ['AXP','GS','JPM','TRV']\n",
    "electronic_tech = ['BA', 'CSCO', 'INTC']\n",
    "producer_manu = ['CAT', 'GE', 'MMM','UTX']\n",
    "minerals = ['CVX','XOM']\n",
    "tech_services = ['IBM', 'MSFT','V']\n",
    "basic_materials = ['DD']\n",
    "consumer_services = ['DIS', 'MCD']\n",
    "retail = ['HD','WMT']\n",
    "health_tech = ['JNJ', 'MRK','PFE']\n",
    "health_services = ['UNH']\n",
    "non_durables = ['KO','NKE','PG']\n",
    "comms = ['T','VZ']\n",
    "\n",
    "industries = [financial, electronic_tech, producer_manu, minerals, consumer_services, tech_services, retail, \n",
    "              health_tech, non_durables, comms]\n",
    "\n",
    "def industrifier(df,list_, drop=True):\n",
    "    for i in range(len(df)):\n",
    "        for e in list_:\n",
    "            for x in e:\n",
    "                if df.loc[i,x] == 1:\n",
    "                    df.loc[i,str(e)] = 1\n",
    "                else:\n",
    "                    pass\n",
    "    if drop==True:\n",
    "        for e in list_:\n",
    "            df.drop(columns=e, inplace=True)\n",
    "        df.fillna(0,inplace=True)\n",
    "    else:\n",
    "        df.fillna(0,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"/Users/jacobbills/Desktop/Economics/Twitter_sentiment_DJIA30/Combined_stocks.csv\") \n",
    "data2 = industrifier(data2, industries, drop=True)\n",
    "sentiments = ['NUM_NEG', 'NUM_NEG1', 'NUM_NEG2', 'NUM_NEG3','NUM_NEU','NUM_NEU1','NUM_NEU2','NUM_NEU3','NUM_POS',\n",
    "              'NUM_POS1','NUM_POS2', 'NUM_POS3']\n",
    "for e in sentiments:\n",
    "    if e.endswith(\"1\"):\n",
    "        data2[e+\"_PER\"] = data2[e]/data2['TW1']\n",
    "    elif e.endswith(\"2\"):\n",
    "        data2[e+\"_PER\"] = data2[e]/data2['TW2']\n",
    "    elif e.endswith(\"3\"):\n",
    "        data2[e+\"_PER\"] = data2[e]/data2['TW3']\n",
    "    else:\n",
    "        data2[e+\"_PER\"] = data2[e]/data2['TW']\n",
    "        \n",
    "data2['Date']= pd.to_datetime(data2['Date'])\n",
    "data2['day'] = data2['Date'].dt.day_name()\n",
    "data2 = pd.get_dummies(data2, columns=['day'])\n",
    "is_null = data2.columns[data2.isnull().any()] # seeing where there might be a problem\n",
    "for e in is_null: #just fill them in with whatever is closest\n",
    "    data2[e].fillna(data2[e].mean(), inplace=True)\n",
    "for i in range(len(data2)): # create the classes\n",
    "    if data2.loc[i,\"CLOSE\"] > data2.loc[i,\"OPEN\"]+.25:\n",
    "        data2.loc[i,\"class\"] = 1 # gained by more than $.25\n",
    "    elif data2.loc[i,\"CLOSE\"] < data2.loc[i,'OPEN']-.25:\n",
    "        data2.loc[i,\"class\"] = 2 # lost by more than $.25 \n",
    "    else:\n",
    "        data2.loc[i,\"class\"] = 0 # minimal change\n",
    "data2 = data2.loc[data2.weekend==0]\n",
    "target2 = data2.CLOSE # target\n",
    "target_class2 = data2[\"class\"] # target for classifiers\n",
    "high2 = data2.HIGH # other columns that we don't really need for now\n",
    "low2 = data2.LOW\n",
    "data2_prev = data2.drop(columns=['CLOSE', 'HIGH', 'LOW', 'Unnamed: 0', 'class', 'day_Saturday', 'day_Sunday', 'Date',\n",
    "                            'NUM_NEG', 'NUM_NEU', 'NUM_POS', 'NUM_NEG_PER', 'NUM_NEU_PER', 'NUM_POS_PER', \"TW\"])\n",
    "data2_nopen_prev = data2_prev.drop(columns=['OPEN'])\n",
    "data2_prev_per = data2_prev.drop(columns=sentiments_prev)\n",
    "data2_noprev_per = data2_nopen_prev.drop(columns=sentiments_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the new data\n",
    "data2_prev_per = pd.DataFrame(data2_prev_per, dtype='float')\n",
    "data2_noprev_per = pd.DataFrame(data2_noprev_per, dtype='float')\n",
    "scaler.fit(data2_prev_per)\n",
    "scaled2_prevperO = scaler.transform(data2_prev_per)\n",
    "\n",
    "scaler.fit(data2_noprev_per)\n",
    "scaled2_prevper = scaler.transform(data2_noprev_per)\n",
    "\n",
    "X_trainPO2, X_testPO2, y_trainPO2, y_testPO2 = train_test_split(scaled2_prevperO, target_class2, test_size=.2, random_state = 11)\n",
    "X_trainP2, X_testP2, y_trainP2, y_testP2 = train_test_split(scaled2_prevper, target_class2, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "Train F1: [0.67320261 0.50408298 0.44565499]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.66      0.58       801\n",
      "         1.0       0.42      0.37      0.39       630\n",
      "         2.0       0.34      0.26      0.29       536\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1967\n",
      "   macro avg       0.43      0.43      0.42      1967\n",
      "weighted avg       0.44      0.46      0.44      1967\n",
      "\n",
      "Train Accuracy: 0.5687221869040051\tTest accuracy: 0.4550076258261312\n",
      "[[525 154 122]\n",
      " [254 233 143]\n",
      " [232 167 137]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors with open industrified\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainPO2, y_trainPO2)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainPO2)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainPO2, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testPO2)\n",
    "print(classification_report(y_testPO2, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainPO2, y_pred_train),\n",
    "                                                     accuracy_score(y_testPO2, y_pred_test)))\n",
    "print(confusion_matrix(y_testPO2, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "Train F1: [0.67362995 0.50144092 0.43826358]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.66      0.58       801\n",
      "         1.0       0.41      0.36      0.39       630\n",
      "         2.0       0.34      0.26      0.30       536\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1967\n",
      "   macro avg       0.43      0.43      0.42      1967\n",
      "weighted avg       0.44      0.45      0.44      1967\n",
      "\n",
      "Train Accuracy: 0.5666878575969485\tTest accuracy: 0.4539908490086426\n",
      "[[526 156 119]\n",
      " [254 227 149]\n",
      " [232 164 140]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors without open industrified\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainP2, y_trainP2)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainP2)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainP2, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testP2)\n",
    "print(classification_report(y_testP2, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainP2, y_pred_train),\n",
    "                                                     accuracy_score(y_testP2, y_pred_test)))\n",
    "print(confusion_matrix(y_testP2, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC industrified open\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainPO2, y_trainPO2)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainPO2)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainPO2, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testPO2)\n",
    "print(classification_report(y_testPO2, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainPO2, y_pred_train),\n",
    "                                                     accuracy_score(y_testPO2, y_pred_test)))\n",
    "print(confusion_matrix(y_testPO2, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC industrified no open\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainP2, y_trainP2)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainP2)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainP2, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testP2)\n",
    "print(classification_report(y_testP2, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainP2, y_pred_train),\n",
    "                                                     accuracy_score(y_testP2, y_pred_test)))\n",
    "print(confusion_matrix(y_testP2, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
