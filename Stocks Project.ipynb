{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning) # get rid of depreciation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/jacobbills/Desktop/Economics/Twitter_sentiment_DJIA30/Combined_stocks.csv\") \n",
    "#brings in the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some percents for the different sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14654 entries, 0 to 14653\n",
      "Data columns (total 56 columns):\n",
      "Unnamed: 0    14654 non-null int64\n",
      "Date          14654 non-null object\n",
      "HIGH          14654 non-null float64\n",
      "CLOSE         14654 non-null float64\n",
      "OPEN          14654 non-null float64\n",
      "LOW           14654 non-null float64\n",
      "NUM_NEG       14654 non-null int64\n",
      "NUM_NEU       14654 non-null int64\n",
      "NUM_POS       14654 non-null int64\n",
      "TW            14654 non-null int64\n",
      "weekend       14654 non-null int64\n",
      "NUM_NEG1      14654 non-null int64\n",
      "NUM_NEG2      14654 non-null int64\n",
      "NUM_NEG3      14654 non-null int64\n",
      "NUM_NEU1      14654 non-null int64\n",
      "NUM_NEU2      14654 non-null int64\n",
      "NUM_NEU3      14654 non-null int64\n",
      "NUM_POS1      14654 non-null int64\n",
      "NUM_POS2      14654 non-null int64\n",
      "NUM_POS3      14654 non-null int64\n",
      "TW1           14654 non-null int64\n",
      "TW2           14654 non-null int64\n",
      "TW3           14654 non-null int64\n",
      "CLOSE1        14654 non-null float64\n",
      "CLOSE2        14654 non-null float64\n",
      "CLOSE3        14654 non-null float64\n",
      "AXP           14654 non-null int64\n",
      "BA            14654 non-null int64\n",
      "CAT           14654 non-null int64\n",
      "CSCO          14654 non-null int64\n",
      "CVX           14654 non-null int64\n",
      "DD            14654 non-null int64\n",
      "DIS           14654 non-null int64\n",
      "GE            14654 non-null int64\n",
      "GS            14654 non-null int64\n",
      "HD            14654 non-null int64\n",
      "IBM           14654 non-null int64\n",
      "INTC          14654 non-null int64\n",
      "JNJ           14654 non-null int64\n",
      "JPM           14654 non-null int64\n",
      "KO            14654 non-null int64\n",
      "MCD           14654 non-null int64\n",
      "MMM           14654 non-null int64\n",
      "MRK           14654 non-null int64\n",
      "MSFT          14654 non-null int64\n",
      "NKE           14654 non-null int64\n",
      "PFE           14654 non-null int64\n",
      "PG            14654 non-null int64\n",
      "T             14654 non-null int64\n",
      "TRV           14654 non-null int64\n",
      "UNH           14654 non-null int64\n",
      "UTX           14654 non-null int64\n",
      "V             14654 non-null int64\n",
      "VZ            14654 non-null int64\n",
      "WMT           14654 non-null int64\n",
      "XOM           14654 non-null int64\n",
      "dtypes: float64(7), int64(48), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #checking what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "sentiments = ['NUM_NEG', 'NUM_NEG1', 'NUM_NEG2','NUM_NEU','NUM_NEU1','NUM_NEU2','NUM_POS','NUM_POS1','NUM_POS2']\n",
    "for e in sentiments:\n",
    "    if e.endswith(\"1\"):\n",
    "        data[e+\"_PER\"] = data[e]/data['TW1']\n",
    "    elif e.endswith(\"2\"):\n",
    "        data[e+\"_PER\"] = data[e]/data['TW2']\n",
    "    else:\n",
    "        data[e+\"_PER\"] = data[e]/data['TW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummies for each day\n",
    "data['Date']= pd.to_datetime(data['Date'])\n",
    "data['day'] = data['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>LOW</th>\n",
       "      <th>NUM_NEG</th>\n",
       "      <th>NUM_NEU</th>\n",
       "      <th>NUM_POS</th>\n",
       "      <th>TW</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_POS_PER</th>\n",
       "      <th>NUM_POS1_PER</th>\n",
       "      <th>NUM_POS2_PER</th>\n",
       "      <th>day_Friday</th>\n",
       "      <th>day_Monday</th>\n",
       "      <th>day_Saturday</th>\n",
       "      <th>day_Sunday</th>\n",
       "      <th>day_Thursday</th>\n",
       "      <th>day_Tuesday</th>\n",
       "      <th>day_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>77.24</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>75.96</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>76.28</td>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>74.64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>74.64</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Date   HIGH  CLOSE   OPEN    LOW  NUM_NEG  NUM_NEU  \\\n",
       "0           0 2013-06-04  77.24  76.02  76.50  75.96        2       12   \n",
       "1           1 2013-06-05  76.28  74.79  76.04  74.64        0        4   \n",
       "2           2 2013-06-06  76.25  76.24  74.75  74.64        1        9   \n",
       "3           3 2013-06-07  78.12  78.03  76.68  76.45        2        4   \n",
       "4           4 2013-06-08  78.12  78.03  76.68  76.45        0        3   \n",
       "\n",
       "   NUM_POS  TW      ...        NUM_POS_PER  NUM_POS1_PER  NUM_POS2_PER  \\\n",
       "0        6  20      ...           0.300000      0.090909      0.000000   \n",
       "1        2   6      ...           0.333333      0.300000      0.090909   \n",
       "2        0  10      ...           0.000000      0.333333      0.300000   \n",
       "3       11  17      ...           0.647059      0.000000      0.333333   \n",
       "4        3   6      ...           0.500000      0.647059      0.000000   \n",
       "\n",
       "   day_Friday  day_Monday  day_Saturday  day_Sunday  day_Thursday  \\\n",
       "0           0           0             0           0             0   \n",
       "1           0           0             0           0             0   \n",
       "2           0           0             0           0             1   \n",
       "3           1           0             0           0             0   \n",
       "4           0           0             1           0             0   \n",
       "\n",
       "   day_Tuesday  day_Wednesday  \n",
       "0            1              0  \n",
       "1            0              1  \n",
       "2            0              0  \n",
       "3            0              0  \n",
       "4            0              0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.get_dummies(data, columns=['day'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NUM_NEG_PER', 'NUM_NEG1_PER', 'NUM_NEG2_PER', 'NUM_NEU_PER',\n",
       "       'NUM_NEU1_PER', 'NUM_NEU2_PER', 'NUM_POS_PER', 'NUM_POS1_PER',\n",
       "       'NUM_POS2_PER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_null = data.columns[data.isnull().any()] # seeing where there might be a problem\n",
    "is_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14654 entries, 0 to 14653\n",
      "Data columns (total 9 columns):\n",
      "NUM_NEG_PER     14620 non-null float64\n",
      "NUM_NEG1_PER    14620 non-null float64\n",
      "NUM_NEG2_PER    14619 non-null float64\n",
      "NUM_NEU_PER     14620 non-null float64\n",
      "NUM_NEU1_PER    14620 non-null float64\n",
      "NUM_NEU2_PER    14619 non-null float64\n",
      "NUM_POS_PER     14620 non-null float64\n",
      "NUM_POS1_PER    14620 non-null float64\n",
      "NUM_POS2_PER    14619 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "data[is_null].info() # about 30 missing for each, for whatever reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in is_null: #just fill them in with whatever is closest\n",
    "    data[e].fillna(data[e].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): # create the classes\n",
    "    if data.loc[i,\"CLOSE\"] > data.loc[i,\"OPEN\"]+.25:\n",
    "        data.loc[i,\"class\"] = 1 # gained by more than $.25\n",
    "    elif data.loc[i,\"CLOSE\"] < data.loc[i,'OPEN']-.25:\n",
    "        data.loc[i,\"class\"] = 2 # lost by more than $.25 \n",
    "    else:\n",
    "        data.loc[i,\"class\"] = 0 # minimal change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>Date</th>\n",
       "      <th>weekend</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>2013-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.27</td>\n",
       "      <td>77.98</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.52</td>\n",
       "      <td>77.61</td>\n",
       "      <td>2013-06-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74.72</td>\n",
       "      <td>76.91</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75.21</td>\n",
       "      <td>74.46</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72.96</td>\n",
       "      <td>74.78</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73.86</td>\n",
       "      <td>73.69</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>74.99</td>\n",
       "      <td>74.10</td>\n",
       "      <td>2013-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.24</td>\n",
       "      <td>74.87</td>\n",
       "      <td>2013-06-19</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72.95</td>\n",
       "      <td>73.76</td>\n",
       "      <td>2013-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73.33</td>\n",
       "      <td>73.38</td>\n",
       "      <td>2013-06-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72.03</td>\n",
       "      <td>72.57</td>\n",
       "      <td>2013-06-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73.23</td>\n",
       "      <td>72.63</td>\n",
       "      <td>2013-06-25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73.91</td>\n",
       "      <td>73.64</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75.14</td>\n",
       "      <td>74.46</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>74.69</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75.64</td>\n",
       "      <td>75.53</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74.62</td>\n",
       "      <td>75.43</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74.37</td>\n",
       "      <td>74.02</td>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14624</th>\n",
       "      <td>99.71</td>\n",
       "      <td>99.55</td>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>99.29</td>\n",
       "      <td>99.80</td>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14626</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14627</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.90</td>\n",
       "      <td>2014-08-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>98.78</td>\n",
       "      <td>98.58</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.12</td>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>99.49</td>\n",
       "      <td>99.78</td>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>99.61</td>\n",
       "      <td>99.04</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>99.45</td>\n",
       "      <td>99.38</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>98.46</td>\n",
       "      <td>99.43</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>99.11</td>\n",
       "      <td>98.86</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>98.36</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14642</th>\n",
       "      <td>99.19</td>\n",
       "      <td>98.74</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14643</th>\n",
       "      <td>97.74</td>\n",
       "      <td>98.92</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14644</th>\n",
       "      <td>97.39</td>\n",
       "      <td>97.80</td>\n",
       "      <td>2014-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>96.82</td>\n",
       "      <td>97.38</td>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14646</th>\n",
       "      <td>97.01</td>\n",
       "      <td>96.32</td>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14647</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14648</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14649</th>\n",
       "      <td>95.77</td>\n",
       "      <td>96.53</td>\n",
       "      <td>2014-09-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>96.28</td>\n",
       "      <td>95.73</td>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14651</th>\n",
       "      <td>97.43</td>\n",
       "      <td>96.23</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14652</th>\n",
       "      <td>97.08</td>\n",
       "      <td>97.83</td>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14653</th>\n",
       "      <td>96.62</td>\n",
       "      <td>97.15</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14654 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLOSE   OPEN       Date  weekend  class\n",
       "0      76.02  76.50 2013-06-04        0    2.0\n",
       "1      74.79  76.04 2013-06-05        0    2.0\n",
       "2      76.24  74.75 2013-06-06        0    1.0\n",
       "3      78.03  76.68 2013-06-07        0    1.0\n",
       "4      78.03  76.68 2013-06-08        1    1.0\n",
       "5      78.03  76.68 2013-06-09        1    1.0\n",
       "6      78.27  77.98 2013-06-10        0    1.0\n",
       "7      76.52  77.61 2013-06-11        0    2.0\n",
       "8      74.72  76.91 2013-06-12        0    2.0\n",
       "9      75.21  74.46 2013-06-13        0    1.0\n",
       "10     72.96  74.78 2013-06-14        0    2.0\n",
       "11     72.96  74.78 2013-06-15        1    2.0\n",
       "12     72.96  74.78 2013-06-16        1    2.0\n",
       "13     73.86  73.69 2013-06-17        0    0.0\n",
       "14     74.99  74.10 2013-06-18        0    1.0\n",
       "15     74.24  74.87 2013-06-19        0    2.0\n",
       "16     72.95  73.76 2013-06-20        0    2.0\n",
       "17     73.33  73.38 2013-06-21        0    0.0\n",
       "18     73.33  73.38 2013-06-22        1    0.0\n",
       "19     73.33  73.38 2013-06-23        1    0.0\n",
       "20     72.03  72.57 2013-06-24        0    2.0\n",
       "21     73.23  72.63 2013-06-25        0    1.0\n",
       "22     73.91  73.64 2013-06-26        0    1.0\n",
       "23     75.14  74.46 2013-06-27        0    1.0\n",
       "24     74.69  75.00 2013-06-28        0    2.0\n",
       "25     74.69  75.00 2013-06-29        1    2.0\n",
       "26     74.69  75.00 2013-06-30        1    2.0\n",
       "27     75.64  75.53 2013-07-01        0    0.0\n",
       "28     74.62  75.43 2013-07-02        0    2.0\n",
       "29     74.37  74.02 2013-07-03        0    1.0\n",
       "...      ...    ...        ...      ...    ...\n",
       "14624  99.71  99.55 2014-08-20        0    0.0\n",
       "14625  99.29  99.80 2014-08-21        0    2.0\n",
       "14626  98.50  98.90 2014-08-22        0    2.0\n",
       "14627  98.50  98.90 2014-08-23        1    2.0\n",
       "14628  98.50  98.90 2014-08-24        1    2.0\n",
       "14629  98.78  98.58 2014-08-25        0    0.0\n",
       "14630  99.65  99.12 2014-08-26        0    1.0\n",
       "14631  99.49  99.78 2014-08-27        0    2.0\n",
       "14632  99.61  99.04 2014-08-28        0    1.0\n",
       "14633  99.45  99.38 2014-08-29        0    0.0\n",
       "14634  99.45  99.38 2014-08-30        1    0.0\n",
       "14635  99.45  99.38 2014-08-31        1    0.0\n",
       "14636  99.45  99.38 2014-09-01        1    0.0\n",
       "14637  98.46  99.43 2014-09-02        0    2.0\n",
       "14638  99.11  98.86 2014-09-03        0    0.0\n",
       "14639  98.36  99.00 2014-09-04        0    2.0\n",
       "14640  99.19  98.74 2014-09-05        0    1.0\n",
       "14641  99.19  98.74 2014-09-06        1    1.0\n",
       "14642  99.19  98.74 2014-09-07        1    1.0\n",
       "14643  97.74  98.92 2014-09-08        0    2.0\n",
       "14644  97.39  97.80 2014-09-09        0    2.0\n",
       "14645  96.82  97.38 2014-09-10        0    2.0\n",
       "14646  97.01  96.32 2014-09-11        0    1.0\n",
       "14647  95.77  96.53 2014-09-12        0    2.0\n",
       "14648  95.77  96.53 2014-09-13        1    2.0\n",
       "14649  95.77  96.53 2014-09-14        1    2.0\n",
       "14650  96.28  95.73 2014-09-15        0    1.0\n",
       "14651  97.43  96.23 2014-09-16        0    1.0\n",
       "14652  97.08  97.83 2014-09-17        0    2.0\n",
       "14653  96.62  97.15 2014-09-18        0    2.0\n",
       "\n",
       "[14654 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"CLOSE\", \"OPEN\", \"Date\", \"weekend\",\"class\"]] #see how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>LOW</th>\n",
       "      <th>NUM_NEG</th>\n",
       "      <th>NUM_NEU</th>\n",
       "      <th>NUM_POS</th>\n",
       "      <th>TW</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_POS1_PER</th>\n",
       "      <th>NUM_POS2_PER</th>\n",
       "      <th>day_Friday</th>\n",
       "      <th>day_Monday</th>\n",
       "      <th>day_Saturday</th>\n",
       "      <th>day_Sunday</th>\n",
       "      <th>day_Thursday</th>\n",
       "      <th>day_Tuesday</th>\n",
       "      <th>day_Wednesday</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>77.24</td>\n",
       "      <td>76.02</td>\n",
       "      <td>76.50</td>\n",
       "      <td>75.96</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>76.28</td>\n",
       "      <td>74.79</td>\n",
       "      <td>76.04</td>\n",
       "      <td>74.64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>76.25</td>\n",
       "      <td>76.24</td>\n",
       "      <td>74.75</td>\n",
       "      <td>74.64</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>78.12</td>\n",
       "      <td>78.03</td>\n",
       "      <td>76.68</td>\n",
       "      <td>76.45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>78.61</td>\n",
       "      <td>78.27</td>\n",
       "      <td>77.98</td>\n",
       "      <td>77.69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Date   HIGH  CLOSE   OPEN    LOW  NUM_NEG  NUM_NEU  \\\n",
       "0           0 2013-06-04  77.24  76.02  76.50  75.96        2       12   \n",
       "1           1 2013-06-05  76.28  74.79  76.04  74.64        0        4   \n",
       "2           2 2013-06-06  76.25  76.24  74.75  74.64        1        9   \n",
       "3           3 2013-06-07  78.12  78.03  76.68  76.45        2        4   \n",
       "6           6 2013-06-10  78.61  78.27  77.98  77.69        0        6   \n",
       "\n",
       "   NUM_POS  TW  ...    NUM_POS1_PER  NUM_POS2_PER  day_Friday  day_Monday  \\\n",
       "0        6  20  ...        0.090909      0.000000           0           0   \n",
       "1        2   6  ...        0.300000      0.090909           0           0   \n",
       "2        0  10  ...        0.333333      0.300000           0           0   \n",
       "3       11  17  ...        0.000000      0.333333           1           0   \n",
       "6        7  13  ...        0.666667      0.500000           0           1   \n",
       "\n",
       "   day_Saturday  day_Sunday  day_Thursday  day_Tuesday  day_Wednesday  class  \n",
       "0             0           0             0            1              0    2.0  \n",
       "1             0           0             0            0              1    2.0  \n",
       "2             0           0             1            0              0    1.0  \n",
       "3             0           0             0            0              0    1.0  \n",
       "6             0           0             0            0              0    1.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.loc[data.weekend==0]\n",
    "data.head() #drop out the weekend data since it doesn't really tell us anything and see if it worked (it did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.CLOSE # target\n",
    "target_class = data[\"class\"] # target for classifiers\n",
    "high = data.HIGH # other columns that we don't really need for now\n",
    "low = data.LOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(columns=['CLOSE', 'HIGH', 'LOW', 'Unnamed: 0', 'class', 'day_Saturday', 'day_Sunday']) # get rid of those ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nodate = data1.drop(columns='Date') # create a df without the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prev = data_nodate.drop(columns=['NUM_NEG', 'NUM_NEU', 'NUM_POS', 'NUM_NEG_PER', 'NUM_NEU_PER', 'NUM_POS_PER', \"TW\"])\n",
    "# create a df without anything for the day of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nopen_date = data_nodate.drop(columns='OPEN')\n",
    "data_nopen_prev = data_prev.drop(columns='OPEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn everything into floats so that scaler is happy\n",
    "\n",
    "data_nodate = pd.DataFrame(data_nodate, dtype='float')\n",
    "data_prev = pd.DataFrame(data_prev, dtype='float')\n",
    "data_nopen_date = pd.DataFrame(data_nopen_date, dtype='float')\n",
    "data_nopen_prev = pd.DataFrame(data_nopen_prev, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10159 entries, 0 to 14653\n",
      "Data columns (total 57 columns):\n",
      "weekend          10159 non-null float64\n",
      "NUM_NEG1         10159 non-null float64\n",
      "NUM_NEG2         10159 non-null float64\n",
      "NUM_NEG3         10159 non-null float64\n",
      "NUM_NEU1         10159 non-null float64\n",
      "NUM_NEU2         10159 non-null float64\n",
      "NUM_NEU3         10159 non-null float64\n",
      "NUM_POS1         10159 non-null float64\n",
      "NUM_POS2         10159 non-null float64\n",
      "NUM_POS3         10159 non-null float64\n",
      "TW1              10159 non-null float64\n",
      "TW2              10159 non-null float64\n",
      "TW3              10159 non-null float64\n",
      "CLOSE1           10159 non-null float64\n",
      "CLOSE2           10159 non-null float64\n",
      "CLOSE3           10159 non-null float64\n",
      "AXP              10159 non-null float64\n",
      "BA               10159 non-null float64\n",
      "CAT              10159 non-null float64\n",
      "CSCO             10159 non-null float64\n",
      "CVX              10159 non-null float64\n",
      "DD               10159 non-null float64\n",
      "DIS              10159 non-null float64\n",
      "GE               10159 non-null float64\n",
      "GS               10159 non-null float64\n",
      "HD               10159 non-null float64\n",
      "IBM              10159 non-null float64\n",
      "INTC             10159 non-null float64\n",
      "JNJ              10159 non-null float64\n",
      "JPM              10159 non-null float64\n",
      "KO               10159 non-null float64\n",
      "MCD              10159 non-null float64\n",
      "MMM              10159 non-null float64\n",
      "MRK              10159 non-null float64\n",
      "MSFT             10159 non-null float64\n",
      "NKE              10159 non-null float64\n",
      "PFE              10159 non-null float64\n",
      "PG               10159 non-null float64\n",
      "T                10159 non-null float64\n",
      "TRV              10159 non-null float64\n",
      "UNH              10159 non-null float64\n",
      "UTX              10159 non-null float64\n",
      "V                10159 non-null float64\n",
      "VZ               10159 non-null float64\n",
      "WMT              10159 non-null float64\n",
      "XOM              10159 non-null float64\n",
      "NUM_NEG1_PER     10159 non-null float64\n",
      "NUM_NEG2_PER     10159 non-null float64\n",
      "NUM_NEU1_PER     10159 non-null float64\n",
      "NUM_NEU2_PER     10159 non-null float64\n",
      "NUM_POS1_PER     10159 non-null float64\n",
      "NUM_POS2_PER     10159 non-null float64\n",
      "day_Friday       10159 non-null float64\n",
      "day_Monday       10159 non-null float64\n",
      "day_Thursday     10159 non-null float64\n",
      "day_Tuesday      10159 non-null float64\n",
      "day_Wednesday    10159 non-null float64\n",
      "dtypes: float64(57)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "data_nopen_prev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is clean, we can try to run some different models on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #scale each of the three sets with open\n",
    "\n",
    "scaler.fit(data_nodate)\n",
    "scaled_df_noo = scaler.transform(data_nodate)\n",
    "\n",
    "scaler.fit(data_prev)\n",
    "scaled_prevo = scaler.transform(data_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into test and training sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(scaled_df_noo, target, test_size=.2, random_state = 11)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(scaled_prevo, target, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_learning_curve(clf, \"Learning Curve\", X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6948907948158737\n",
      "Test MSE: 0.6032102402205742\n"
     ]
    }
   ],
   "source": [
    "# elastic net without dates\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train1, y_train1)\n",
    "train_predictions = clf.predict(X_train1)\n",
    "test_predictions = clf.predict(X_test1)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train1, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test1, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM_NEG', -0.0),\n",
       " ('NUM_NEU', -0.0),\n",
       " ('NUM_POS', 0.0),\n",
       " ('TW', -0.0),\n",
       " ('weekend', 0.0),\n",
       " ('NUM_NEG1', -0.0),\n",
       " ('NUM_NEG2', 0.0),\n",
       " ('NUM_NEG3', 0.0),\n",
       " ('NUM_NEU1', -0.0),\n",
       " ('NUM_NEU2', -0.0),\n",
       " ('NUM_NEU3', -0.0),\n",
       " ('NUM_POS1', -0.0),\n",
       " ('NUM_POS2', 0.0),\n",
       " ('NUM_POS3', 0.0),\n",
       " ('TW1', -0.0),\n",
       " ('TW2', 0.0),\n",
       " ('TW3', 0.0),\n",
       " ('CLOSE2', 0.0),\n",
       " ('CLOSE3', 0.0),\n",
       " ('AXP', -0.0),\n",
       " ('BA', 0.0),\n",
       " ('CAT', 0.0),\n",
       " ('CSCO', -0.0),\n",
       " ('CVX', 0.0),\n",
       " ('DD', -0.0),\n",
       " ('DIS', -0.0),\n",
       " ('GE', -0.0),\n",
       " ('GS', 0.0),\n",
       " ('HD', -0.0),\n",
       " ('IBM', 0.0),\n",
       " ('INTC', -0.0),\n",
       " ('JNJ', 0.0),\n",
       " ('JPM', -0.0),\n",
       " ('KO', -0.0),\n",
       " ('MCD', 0.0),\n",
       " ('MMM', 0.0),\n",
       " ('MRK', -0.0),\n",
       " ('MSFT', -0.0),\n",
       " ('NKE', -0.0),\n",
       " ('PFE', -0.0),\n",
       " ('PG', -0.0),\n",
       " ('T', -0.0),\n",
       " ('TRV', 0.0),\n",
       " ('UNH', 0.0),\n",
       " ('UTX', 0.0),\n",
       " ('V', 0.0),\n",
       " ('VZ', -0.0),\n",
       " ('WMT', 0.0),\n",
       " ('XOM', 0.0),\n",
       " ('NUM_NEG1_PER', -0.0),\n",
       " ('NUM_NEG2_PER', 0.0),\n",
       " ('NUM_NEU_PER', -0.0),\n",
       " ('NUM_NEU1_PER', 0.0),\n",
       " ('NUM_NEU2_PER', -0.0),\n",
       " ('NUM_POS1_PER', -0.0),\n",
       " ('NUM_POS2_PER', 0.0),\n",
       " ('day_Friday', 0.0),\n",
       " ('day_Monday', -0.0),\n",
       " ('day_Thursday', -0.0),\n",
       " ('day_Tuesday', -0.0),\n",
       " ('day_Wednesday', 0.0),\n",
       " ('CLOSE1', 0.000500390133490317),\n",
       " ('NUM_POS_PER', 0.006114901424223976),\n",
       " ('NUM_NEG_PER', -0.017814296221278735),\n",
       " ('OPEN', 45.02708238077944)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above\n",
    "sorted(list(zip(data_nodate, clf.coef_)), key=lambda x: abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.7003492633051123\n",
      "Test MSE: 0.6075214545452414\n"
     ]
    }
   ],
   "source": [
    "# elastic net without today's data\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train2, y_train2)\n",
    "train_predictions = clf.predict(X_train2)\n",
    "test_predictions = clf.predict(X_test2)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train2, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test2, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weekend', 0.0),\n",
       " ('NUM_NEG1', -0.0),\n",
       " ('NUM_NEG2', 0.0),\n",
       " ('NUM_NEG3', 0.0),\n",
       " ('NUM_NEU1', -0.0),\n",
       " ('NUM_NEU2', -0.0),\n",
       " ('NUM_NEU3', -0.0),\n",
       " ('NUM_POS1', -0.0),\n",
       " ('NUM_POS2', 0.0),\n",
       " ('NUM_POS3', 0.0),\n",
       " ('TW1', -0.0),\n",
       " ('TW2', 0.0),\n",
       " ('TW3', 0.0),\n",
       " ('CLOSE2', 0.0),\n",
       " ('CLOSE3', 0.0),\n",
       " ('AXP', -0.0),\n",
       " ('BA', 0.0),\n",
       " ('CAT', 0.0),\n",
       " ('CSCO', -0.0),\n",
       " ('CVX', 0.0),\n",
       " ('DD', -0.0),\n",
       " ('DIS', -0.0),\n",
       " ('GE', -0.0),\n",
       " ('GS', 0.0),\n",
       " ('HD', -0.0),\n",
       " ('IBM', 0.0),\n",
       " ('INTC', -0.0),\n",
       " ('JNJ', 0.0),\n",
       " ('JPM', -0.0),\n",
       " ('KO', -0.0),\n",
       " ('MCD', 0.0),\n",
       " ('MMM', 0.0),\n",
       " ('MRK', -0.0),\n",
       " ('MSFT', -0.0),\n",
       " ('NKE', -0.0),\n",
       " ('PFE', -0.0),\n",
       " ('PG', -0.0),\n",
       " ('T', -0.0),\n",
       " ('TRV', 0.0),\n",
       " ('UNH', 0.0),\n",
       " ('UTX', 0.0),\n",
       " ('V', 0.0),\n",
       " ('VZ', -0.0),\n",
       " ('WMT', 0.0),\n",
       " ('XOM', 0.0),\n",
       " ('NUM_NEG1_PER', -0.0),\n",
       " ('NUM_NEG2_PER', 0.0),\n",
       " ('NUM_NEU1_PER', 0.0),\n",
       " ('NUM_NEU2_PER', -0.0),\n",
       " ('NUM_POS1_PER', -0.0),\n",
       " ('NUM_POS2_PER', 0.0),\n",
       " ('day_Friday', 0.0),\n",
       " ('day_Monday', -0.0),\n",
       " ('day_Thursday', -0.0),\n",
       " ('day_Tuesday', -0.0),\n",
       " ('day_Wednesday', 0.0),\n",
       " ('CLOSE1', 0.0004528626066566547),\n",
       " ('OPEN', 45.02575353669932)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(data_prev, clf.coef_)), key=lambda x: abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data wihtout open\n",
    "scaler.fit(data_nopen_date)\n",
    "scaled_df_non = scaler.transform(data_nopen_date)\n",
    "\n",
    "scaler.fit(data_nopen_prev)\n",
    "scaled_prevn = scaler.transform(data_nopen_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training sets\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(scaled_df_non, target, test_size=.2, random_state = 11)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(scaled_prevn, target, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.9595445780301854\n",
      "Test MSE: 0.7892448797690244\n",
      "[('NUM_NEG', -0.0), ('NUM_NEU', -0.0), ('NUM_POS', 0.0), ('TW', -0.0), ('weekend', 0.0), ('NUM_NEG1', -0.0), ('NUM_NEG2', 0.0), ('NUM_NEG3', 0.0), ('NUM_NEU1', -0.0), ('NUM_NEU2', -0.0), ('NUM_NEU3', -0.0), ('NUM_POS1', -0.0), ('NUM_POS2', -0.0), ('NUM_POS3', 0.0), ('TW1', -0.0), ('TW2', -0.0), ('TW3', -0.0), ('AXP', -0.0), ('BA', 0.0), ('CAT', 0.0), ('CSCO', -0.0), ('CVX', 0.0), ('DD', -0.0), ('DIS', -0.0), ('GE', -0.0), ('GS', 0.0), ('HD', -0.0), ('IBM', 0.0), ('INTC', -0.0), ('JNJ', 0.0), ('JPM', 0.0), ('KO', -0.0), ('MCD', 0.0), ('MMM', 0.0), ('MRK', -0.0), ('MSFT', -0.0), ('NKE', -0.0), ('PFE', -0.0), ('PG', -0.0), ('T', -0.0), ('TRV', 0.0), ('UNH', -0.0), ('UTX', 0.0), ('V', 0.0), ('VZ', -0.0), ('WMT', 0.0), ('XOM', 0.0), ('NUM_NEG1_PER', -0.0), ('NUM_NEG2_PER', 0.0), ('NUM_NEU_PER', -0.0), ('NUM_NEU1_PER', 0.0), ('NUM_NEU2_PER', -0.0), ('NUM_POS1_PER', -0.0), ('NUM_POS2_PER', 0.0), ('day_Friday', 0.0), ('day_Monday', 0.0), ('day_Thursday', -0.0), ('day_Tuesday', 0.0), ('day_Wednesday', -0.0), ('CLOSE3', 0.0010848610765953413), ('CLOSE2', 0.0015949122914042718), ('NUM_POS_PER', 0.056523673131179786), ('NUM_NEG_PER', -0.09928821725955493), ('CLOSE1', 45.01708623918913)]\n"
     ]
    }
   ],
   "source": [
    "# Elastic net with no dates\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train4, y_train4)\n",
    "train_predictions = clf.predict(X_train4)\n",
    "test_predictions = clf.predict(X_test4)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train4, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test4, test_predictions)))\n",
    "print(sorted(list(zip(data_nopen_date, clf.coef_)), key=lambda x: abs(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 1.0074518870082958\n",
      "Test MSE: 0.8312475875546196\n",
      "[('weekend', 0.0), ('NUM_NEG1', -0.0), ('NUM_NEG2', -0.0), ('NUM_NEG3', 0.0), ('NUM_NEU1', -0.0), ('NUM_NEU2', -0.0), ('NUM_NEU3', -0.0), ('NUM_POS1', -0.0), ('NUM_POS2', -0.0), ('NUM_POS3', 0.0), ('TW1', -0.0), ('TW2', -0.0), ('TW3', -0.0), ('CLOSE2', 0.0), ('AXP', -0.0), ('BA', 0.0), ('CAT', 0.0), ('CSCO', -0.0), ('CVX', 0.0), ('DD', -0.0), ('DIS', 0.0), ('GE', -0.0), ('GS', 0.0), ('HD', -0.0), ('IBM', 0.0), ('INTC', -0.0), ('JNJ', 0.0), ('JPM', -0.0), ('KO', -0.0), ('MCD', -0.0), ('MMM', 0.0), ('MRK', -0.0), ('MSFT', -0.0), ('NKE', 0.0), ('PFE', -0.0), ('PG', -0.0), ('T', -0.0), ('TRV', 0.0), ('UNH', 0.0), ('UTX', 0.0), ('V', 0.0), ('VZ', -0.0), ('WMT', -0.0), ('XOM', 0.0), ('NUM_NEG1_PER', -0.0), ('NUM_NEG2_PER', 0.0), ('NUM_NEU1_PER', 0.0), ('NUM_NEU2_PER', -0.0), ('NUM_POS1_PER', 0.0), ('NUM_POS2_PER', 0.0), ('day_Friday', 0.0), ('day_Monday', 0.0), ('day_Thursday', -0.0), ('day_Tuesday', 0.0), ('day_Wednesday', -0.0), ('CLOSE3', 0.0004296310167129904), ('CLOSE1', 45.012043066088715)]\n"
     ]
    }
   ],
   "source": [
    "# elastic net without anything from the day being predicted\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .3, .5, .7, .8, .9, .95, .99, 1], alphas= [.1, 1, 5, 10], cv=5) #basic Elastic Net with CV\n",
    "clf.fit(X_train5, y_train5)\n",
    "train_predictions = clf.predict(X_train5)\n",
    "test_predictions = clf.predict(X_test5)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train5, train_predictions)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test5, test_predictions)))\n",
    "print(sorted(list(zip(data_nopen_prev, clf.coef_)), key=lambda x: abs(x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, it isn't very interesting to use the data to predict future prices because it ends up that basically the only thing you want to know is what the opening price/yesterday's price is, and then how people were tweeting the day of (possibly after closing). So instead we'll try to predict if tweets can forecast if the stock is going to go up or down. The \"previous\" data is the most important sort here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #Nearest Neighbors\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, GaussianNB # different Bayesian models\n",
    "from sklearn.svm import SVC #support vector machine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier #ensemble models\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV #to do cross validation\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error #different ways of scoring\n",
    "from sklearn.metrics import classification_report # classification report\n",
    "from sklearn.metrics import confusion_matrix # confusion matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training sets from the previous day data (with and without OPEN)\n",
    "X_traincO, X_testcO, y_traincO, y_testcO = train_test_split(scaled_prevo, target_class, test_size=.2, random_state = 11)\n",
    "X_trainc, X_testc, y_trainc, y_testc = train_test_split(scaled_prevn, target_class, test_size=.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 3, 'weights': 'distance'}\n",
      "Train F1: [1. 1. 1.]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.65      0.59       810\n",
      "         1.0       0.42      0.43      0.43       630\n",
      "         2.0       0.39      0.29      0.33       592\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      2032\n",
      "   macro avg       0.45      0.45      0.45      2032\n",
      "weighted avg       0.46      0.47      0.46      2032\n",
      "\n",
      "Train Accuracy: 1.0\tTest accuracy: 0.4749015748031496\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors with open\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_traincO, y_traincO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_traincO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_traincO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testcO)\n",
    "print(classification_report(y_testcO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_traincO, y_pred_train),\n",
    "                                                     accuracy_score(y_testcO, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[525, 166, 119],\n",
       "       [215, 271, 144],\n",
       "       [222, 201, 169]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matric to evaluate performance\n",
    "confusion_matrix(y_testcO, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 11, 'p': 3, 'weights': 'distance'}\n",
      "Train F1: [1. 1. 1.]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.65      0.59       810\n",
      "         1.0       0.43      0.43      0.43       630\n",
      "         2.0       0.39      0.29      0.33       592\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      2032\n",
      "   macro avg       0.46      0.46      0.45      2032\n",
      "weighted avg       0.46      0.48      0.47      2032\n",
      "\n",
      "Train Accuracy: 1.0\tTest accuracy: 0.4763779527559055\n",
      "[[525 165 120]\n",
      " [212 272 146]\n",
      " [220 201 171]]\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors without open\n",
    "knn = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(knn, {\"n_neighbors\": [5, 7, 9, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainc, y_trainc)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainc)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainc, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testc)\n",
    "print(classification_report(y_testc, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainc, y_pred_train),\n",
    "                                                     accuracy_score(y_testc, y_pred_test)))\n",
    "print(confusion_matrix(y_testc, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first of all this model is way overfitting, so that needs to be fixed. Removing \"OPEN\" made it only marginally better (talking like 2 more true positives for each class) so that indicates that OPEN is not a driving force for this problem (unlike the basic prediction problem). Secondly, it seems to mostly put things in the first class (no major change) which works okay but not great. It is really bad at predicting a drop in prices, so I'm not sure what is going on there, except that it probaly trained itself to mostly put things in the first class. I'll try a random forest, since we can get feature importances from that which may give valuable information about what variables to keep and what ones to drop so that we stop overfitting the nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'class_weight': 'balanced', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 500, 'random_state': 9}\n",
      "Train F1: [0.66584982 0.76710796 0.73928158]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.53      0.58       810\n",
      "         1.0       0.38      0.40      0.39       630\n",
      "         2.0       0.33      0.39      0.36       592\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      2032\n",
      "   macro avg       0.45      0.44      0.44      2032\n",
      "weighted avg       0.47      0.45      0.46      2032\n",
      "\n",
      "Train Accuracy: 0.7226528854435831\tTest accuracy: 0.4498031496062992\n",
      "[[426 171 213]\n",
      " [121 255 254]\n",
      " [114 245 233]]\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with Open\n",
    "rfc = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_traincO, y_traincO)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_traincO)\n",
    "print(\"Train F1: {}\".format(f1_score(y_traincO, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testcO)\n",
    "print(classification_report(y_testcO, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_traincO, y_pred_train),\n",
    "                                                     accuracy_score(y_testcO, y_pred_test)))\n",
    "print(confusion_matrix(y_testcO, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcb = RandomForestClassifier(n_estimators = 500, max_features='sqrt', min_samples_leaf=3, max_depth\n",
    "                             = 11, class_weight='balanced')\n",
    "rfcb.fit(X_traincO, y_traincO)\n",
    "feature_imp_rfc1 = sorted(list(zip(data_prev, rfcb.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier without Open\n",
    "gridsearch = GridSearchCV(rfc, {\"n_estimators\": [20, 50, 100, 200, 500], \"max_depth\": [1, 3, 5, 7, 9, 11], \n",
    "                                 \"min_samples_leaf\": [3 , 5 , 7 , 9], \"max_features\": [None, 'sqrt', 'log2']\n",
    "                                , \"class_weight\": [\"balanced\", \"balanced_subsample\"], 'random_state': [9]}, \n",
    "                          scoring='f1_micro', cv=3)\n",
    "gridsearch.fit(X_trainc, y_trainc)\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_trainc)\n",
    "print(\"Train F1: {}\".format(f1_score(y_trainc, y_pred_train, average=None)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_testc)\n",
    "print(classification_report(y_testc, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_trainc, y_pred_train),\n",
    "                                                     accuracy_score(y_testc, y_pred_test)))\n",
    "print(confusion_matrix(y_testc, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcb2 = RandomForestClassifier()\n",
    "feature_imp_rfc2 = sorted(list(zip(data_nopen_prev, rfcb2.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now use an old set of functions I wrote to get plot out the most important features and then decide how to engineer from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_extract(dic):\n",
    "    y = pd.DataFrame.from_dict(dic, orient='index') #turns the dictionary into a data frame\n",
    "    y = y.index # list of the names in the dataframe\n",
    "    return y\n",
    "\n",
    "def feature_extract(data_frame, feature_importances, sensitivity): # function to extract a list of features above a given sensitivty\n",
    "    coef_dict = dict((zip(data_frame, feature_importances))) #creates a dictionary from the model's feature importance\n",
    "    coef_list = {} # another dictionary\n",
    "    for key in coef_dict: # runs through the zipped dictionary \n",
    "        x = coef_dict.get(key) # extracts value for the key\n",
    "        if abs(x) > sensitivity:  # if the absolute value is bigger than the sensitivity\n",
    "            coef_list[key] = x # adds a new entry to the other dictionary \n",
    "        else: # if the coefficient isn't big enough\n",
    "            pass # move to the next key\n",
    "    coef_list = key_extract(coef_list) # uses a previous function I wrote to make a list of the names of those coeff\n",
    "    return coef_list # returns that list\n",
    "\n",
    "def best_feature_dict(list_, features_imp): #creates a dictionary from a list of tuples using another list of names\n",
    "    y = {}\n",
    "    for e in list_:\n",
    "        y[e] = dict(features_imp).get(e)\n",
    "    return y\n",
    "\n",
    "def best_feature_plot(list_, features_imp, ticks=90): #plots the features importances\n",
    "    y = best_feature_dict(list_, features_imp)\n",
    "    plt.bar(y.keys(),y.values())\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xticks(rotation=ticks)\n",
    "    plt.ylabel(\"Percent Used\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "def features_full(data_frame, feature_importances, sensitivity): #combines these functions into one nice one\n",
    "    x = feature_extract(data_frame, feature_importances, sensitivity)\n",
    "    z = sorted(list(zip(data_frame, feature_importances)), key=lambda x: x[1], reverse=True)\n",
    "    y = best_feature_plot(x, z)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_feat1, best_featplt1 = features_full(data_prev, rfcb.feature_importances_, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
